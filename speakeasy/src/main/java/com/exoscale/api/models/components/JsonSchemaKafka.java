/* 
 * Code generated by Speakeasy (https://speakeasyapi.dev). DO NOT EDIT.
 */

package com.exoscale.api.models.components;

import com.exoscale.api.utils.Utils;
import com.fasterxml.jackson.annotation.JsonFormat;
import com.fasterxml.jackson.annotation.JsonInclude.Include;
import com.fasterxml.jackson.annotation.JsonInclude;
import com.fasterxml.jackson.annotation.JsonProperty;
import com.fasterxml.jackson.core.type.TypeReference;
import java.io.InputStream;
import java.lang.Deprecated;
import java.math.BigDecimal;
import java.math.BigInteger;
import java.util.Optional;


public class JsonSchemaKafka {

    /**
     * The (optional) comma-delimited setting for the broker to use to verify that the JWT was issued for one of the expected audiences.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("sasl_oauthbearer_expected_audience")
    private Optional<? extends String> saslOauthbearerExpectedAudience;

    /**
     * The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("group_max_session_timeout_ms")
    private Optional<? extends Long> groupMaxSessionTimeoutMs;

    /**
     * The number of messages accumulated on a log partition before messages are flushed to disk
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_flush_interval_messages")
    private Optional<? extends Long> logFlushIntervalMessages;

    /**
     * OIDC JWKS endpoint URL. By setting this the SASL SSL OAuth2/OIDC authentication is enabled. See also other options for SASL OAuth2/OIDC. 
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("sasl_oauthbearer_jwks_endpoint_url")
    private Optional<? extends String> saslOauthbearerJwksEndpointUrl;

    /**
     * The maximum number of connections allowed from each ip address (defaults to 2147483647).
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("max_connections_per_ip")
    private Optional<? extends Long> maxConnectionsPerIp;

    /**
     * Optional setting for the broker to use to verify that the JWT was created by the expected issuer.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("sasl_oauthbearer_expected_issuer")
    private Optional<? extends String> saslOauthbearerExpectedIssuer;

    /**
     * The maximum size in bytes of the offset index
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_index_size_max_bytes")
    private Optional<? extends Long> logIndexSizeMaxBytes;

    /**
     * Enable auto creation of topics
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("auto_create_topics_enable")
    private Optional<? extends Boolean> autoCreateTopicsEnable;

    /**
     * The interval with which Kafka adds an entry to the offset index
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_index_interval_bytes")
    private Optional<? extends Long> logIndexIntervalBytes;

    /**
     * The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("replica_fetch_max_bytes")
    private Optional<? extends Long> replicaFetchMaxBytes;

    /**
     * Number of partitions for autocreated topics
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("num_partitions")
    private Optional<? extends Long> numPartitions;

    /**
     * The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("transaction_state_log_segment_bytes")
    private Optional<? extends Long> transactionStateLogSegmentBytes;

    /**
     * Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("replica_fetch_response_max_bytes")
    private Optional<? extends Long> replicaFetchResponseMaxBytes;

    /**
     * Define whether the timestamp in the message is message create time or log append time.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_message_timestamp_type")
    private Optional<? extends LogMessageTimestampType> logMessageTimestampType;

    /**
     * Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("connections_max_idle_ms")
    private Optional<? extends Long> connectionsMaxIdleMs;

    /**
     * The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_flush_interval_ms")
    private Optional<? extends Long> logFlushIntervalMs;

    /**
     * Should pre allocate file when create new segment?
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_preallocate")
    private Optional<? extends Boolean> logPreallocate;

    /**
     * The amount of time to wait before deleting a file from the filesystem
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_segment_delete_delay_ms")
    private Optional<? extends Long> logSegmentDeleteDelayMs;

    /**
     * The maximum size of message that the server can receive.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("message_max_bytes")
    private Optional<? extends Long> messageMaxBytes;

    /**
     * The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("group_initial_rebalance_delay_ms")
    private Optional<? extends Long> groupInitialRebalanceDelayMs;

    /**
     * The maximum size of local log segments that can grow for a partition before it gets eligible for deletion. If set to -2, the value of log.retention.bytes is used. The effective value should always be less than or equal to log.retention.bytes value.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_local_retention_bytes")
    private Optional<? extends Long> logLocalRetentionBytes;

    /**
     * The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_roll_jitter_ms")
    private Optional<? extends Long> logRollJitterMs;

    /**
     * The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("transaction_remove_expired_transaction_cleanup_interval_ms")
    private Optional<? extends Long> transactionRemoveExpiredTransactionCleanupIntervalMs;

    /**
     * Replication factor for autocreated topics
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("default_replication_factor")
    private Optional<? extends Long> defaultReplicationFactor;

    /**
     * The maximum time before a new log segment is rolled out (in milliseconds).
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_roll_ms")
    private Optional<? extends Long> logRollMs;

    /**
     * The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("producer_purgatory_purge_interval_requests")
    private Optional<? extends Long> producerPurgatoryPurgeIntervalRequests;

    /**
     * The maximum size of the log before deleting messages
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_retention_bytes")
    private Optional<? extends Long> logRetentionBytes;

    /**
     * When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("min_insync_replicas")
    private Optional<? extends Long> minInsyncReplicas;

    /**
     * Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("compression_type")
    private Optional<? extends CompressionType> compressionType;

    /**
     * The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_message_timestamp_difference_max_ms")
    private Optional<? extends Long> logMessageTimestampDifferenceMaxMs;

    /**
     * The number of milliseconds to keep the local log segments before it gets eligible for deletion. If set to -2, the value of log.retention.ms is used. The effective value should always be less than or equal to log.retention.ms value.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_local_retention_ms")
    private Optional<? extends Long> logLocalRetentionMs;

    /**
     * This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. 
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_message_downconversion_enable")
    private Optional<? extends Boolean> logMessageDownconversionEnable;

    /**
     * Name of the scope from which to extract the subject claim from the JWT. Defaults to sub.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("sasl_oauthbearer_sub_claim_name")
    private Optional<? extends String> saslOauthbearerSubClaimName;

    /**
     * The maximum number of incremental fetch sessions that the broker will maintain.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("max_incremental_fetch_session_cache_slots")
    private Optional<? extends Long> maxIncrementalFetchSessionCacheSlots;

    /**
     * The number of hours to keep a log file before deleting it
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_retention_hours")
    private Optional<? extends Long> logRetentionHours;

    /**
     * The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("group_min_session_timeout_ms")
    private Optional<? extends Long> groupMinSessionTimeoutMs;

    /**
     * The maximum number of bytes in a socket request (defaults to 104857600).
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("socket_request_max_bytes")
    private Optional<? extends Long> socketRequestMaxBytes;

    /**
     * The maximum size of a single log file
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_segment_bytes")
    private Optional<? extends Long> logSegmentBytes;

    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log-cleanup-and-compaction")
    private Optional<? extends ConfigureLogCleanerForTopicCompaction> logCleanupAndCompaction;

    /**
     * Log retention window in minutes for offsets topic
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("offsets_retention_minutes")
    private Optional<? extends Long> offsetsRetentionMinutes;

    /**
     * The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
     */
    @JsonInclude(Include.NON_ABSENT)
    @JsonProperty("log_retention_ms")
    private Optional<? extends Long> logRetentionMs;

    public JsonSchemaKafka(
            @JsonProperty("sasl_oauthbearer_expected_audience") Optional<? extends String> saslOauthbearerExpectedAudience,
            @JsonProperty("group_max_session_timeout_ms") Optional<? extends Long> groupMaxSessionTimeoutMs,
            @JsonProperty("log_flush_interval_messages") Optional<? extends Long> logFlushIntervalMessages,
            @JsonProperty("sasl_oauthbearer_jwks_endpoint_url") Optional<? extends String> saslOauthbearerJwksEndpointUrl,
            @JsonProperty("max_connections_per_ip") Optional<? extends Long> maxConnectionsPerIp,
            @JsonProperty("sasl_oauthbearer_expected_issuer") Optional<? extends String> saslOauthbearerExpectedIssuer,
            @JsonProperty("log_index_size_max_bytes") Optional<? extends Long> logIndexSizeMaxBytes,
            @JsonProperty("auto_create_topics_enable") Optional<? extends Boolean> autoCreateTopicsEnable,
            @JsonProperty("log_index_interval_bytes") Optional<? extends Long> logIndexIntervalBytes,
            @JsonProperty("replica_fetch_max_bytes") Optional<? extends Long> replicaFetchMaxBytes,
            @JsonProperty("num_partitions") Optional<? extends Long> numPartitions,
            @JsonProperty("transaction_state_log_segment_bytes") Optional<? extends Long> transactionStateLogSegmentBytes,
            @JsonProperty("replica_fetch_response_max_bytes") Optional<? extends Long> replicaFetchResponseMaxBytes,
            @JsonProperty("log_message_timestamp_type") Optional<? extends LogMessageTimestampType> logMessageTimestampType,
            @JsonProperty("connections_max_idle_ms") Optional<? extends Long> connectionsMaxIdleMs,
            @JsonProperty("log_flush_interval_ms") Optional<? extends Long> logFlushIntervalMs,
            @JsonProperty("log_preallocate") Optional<? extends Boolean> logPreallocate,
            @JsonProperty("log_segment_delete_delay_ms") Optional<? extends Long> logSegmentDeleteDelayMs,
            @JsonProperty("message_max_bytes") Optional<? extends Long> messageMaxBytes,
            @JsonProperty("group_initial_rebalance_delay_ms") Optional<? extends Long> groupInitialRebalanceDelayMs,
            @JsonProperty("log_local_retention_bytes") Optional<? extends Long> logLocalRetentionBytes,
            @JsonProperty("log_roll_jitter_ms") Optional<? extends Long> logRollJitterMs,
            @JsonProperty("transaction_remove_expired_transaction_cleanup_interval_ms") Optional<? extends Long> transactionRemoveExpiredTransactionCleanupIntervalMs,
            @JsonProperty("default_replication_factor") Optional<? extends Long> defaultReplicationFactor,
            @JsonProperty("log_roll_ms") Optional<? extends Long> logRollMs,
            @JsonProperty("producer_purgatory_purge_interval_requests") Optional<? extends Long> producerPurgatoryPurgeIntervalRequests,
            @JsonProperty("log_retention_bytes") Optional<? extends Long> logRetentionBytes,
            @JsonProperty("min_insync_replicas") Optional<? extends Long> minInsyncReplicas,
            @JsonProperty("compression_type") Optional<? extends CompressionType> compressionType,
            @JsonProperty("log_message_timestamp_difference_max_ms") Optional<? extends Long> logMessageTimestampDifferenceMaxMs,
            @JsonProperty("log_local_retention_ms") Optional<? extends Long> logLocalRetentionMs,
            @JsonProperty("log_message_downconversion_enable") Optional<? extends Boolean> logMessageDownconversionEnable,
            @JsonProperty("sasl_oauthbearer_sub_claim_name") Optional<? extends String> saslOauthbearerSubClaimName,
            @JsonProperty("max_incremental_fetch_session_cache_slots") Optional<? extends Long> maxIncrementalFetchSessionCacheSlots,
            @JsonProperty("log_retention_hours") Optional<? extends Long> logRetentionHours,
            @JsonProperty("group_min_session_timeout_ms") Optional<? extends Long> groupMinSessionTimeoutMs,
            @JsonProperty("socket_request_max_bytes") Optional<? extends Long> socketRequestMaxBytes,
            @JsonProperty("log_segment_bytes") Optional<? extends Long> logSegmentBytes,
            @JsonProperty("log-cleanup-and-compaction") Optional<? extends ConfigureLogCleanerForTopicCompaction> logCleanupAndCompaction,
            @JsonProperty("offsets_retention_minutes") Optional<? extends Long> offsetsRetentionMinutes,
            @JsonProperty("log_retention_ms") Optional<? extends Long> logRetentionMs) {
        Utils.checkNotNull(saslOauthbearerExpectedAudience, "saslOauthbearerExpectedAudience");
        Utils.checkNotNull(groupMaxSessionTimeoutMs, "groupMaxSessionTimeoutMs");
        Utils.checkNotNull(logFlushIntervalMessages, "logFlushIntervalMessages");
        Utils.checkNotNull(saslOauthbearerJwksEndpointUrl, "saslOauthbearerJwksEndpointUrl");
        Utils.checkNotNull(maxConnectionsPerIp, "maxConnectionsPerIp");
        Utils.checkNotNull(saslOauthbearerExpectedIssuer, "saslOauthbearerExpectedIssuer");
        Utils.checkNotNull(logIndexSizeMaxBytes, "logIndexSizeMaxBytes");
        Utils.checkNotNull(autoCreateTopicsEnable, "autoCreateTopicsEnable");
        Utils.checkNotNull(logIndexIntervalBytes, "logIndexIntervalBytes");
        Utils.checkNotNull(replicaFetchMaxBytes, "replicaFetchMaxBytes");
        Utils.checkNotNull(numPartitions, "numPartitions");
        Utils.checkNotNull(transactionStateLogSegmentBytes, "transactionStateLogSegmentBytes");
        Utils.checkNotNull(replicaFetchResponseMaxBytes, "replicaFetchResponseMaxBytes");
        Utils.checkNotNull(logMessageTimestampType, "logMessageTimestampType");
        Utils.checkNotNull(connectionsMaxIdleMs, "connectionsMaxIdleMs");
        Utils.checkNotNull(logFlushIntervalMs, "logFlushIntervalMs");
        Utils.checkNotNull(logPreallocate, "logPreallocate");
        Utils.checkNotNull(logSegmentDeleteDelayMs, "logSegmentDeleteDelayMs");
        Utils.checkNotNull(messageMaxBytes, "messageMaxBytes");
        Utils.checkNotNull(groupInitialRebalanceDelayMs, "groupInitialRebalanceDelayMs");
        Utils.checkNotNull(logLocalRetentionBytes, "logLocalRetentionBytes");
        Utils.checkNotNull(logRollJitterMs, "logRollJitterMs");
        Utils.checkNotNull(transactionRemoveExpiredTransactionCleanupIntervalMs, "transactionRemoveExpiredTransactionCleanupIntervalMs");
        Utils.checkNotNull(defaultReplicationFactor, "defaultReplicationFactor");
        Utils.checkNotNull(logRollMs, "logRollMs");
        Utils.checkNotNull(producerPurgatoryPurgeIntervalRequests, "producerPurgatoryPurgeIntervalRequests");
        Utils.checkNotNull(logRetentionBytes, "logRetentionBytes");
        Utils.checkNotNull(minInsyncReplicas, "minInsyncReplicas");
        Utils.checkNotNull(compressionType, "compressionType");
        Utils.checkNotNull(logMessageTimestampDifferenceMaxMs, "logMessageTimestampDifferenceMaxMs");
        Utils.checkNotNull(logLocalRetentionMs, "logLocalRetentionMs");
        Utils.checkNotNull(logMessageDownconversionEnable, "logMessageDownconversionEnable");
        Utils.checkNotNull(saslOauthbearerSubClaimName, "saslOauthbearerSubClaimName");
        Utils.checkNotNull(maxIncrementalFetchSessionCacheSlots, "maxIncrementalFetchSessionCacheSlots");
        Utils.checkNotNull(logRetentionHours, "logRetentionHours");
        Utils.checkNotNull(groupMinSessionTimeoutMs, "groupMinSessionTimeoutMs");
        Utils.checkNotNull(socketRequestMaxBytes, "socketRequestMaxBytes");
        Utils.checkNotNull(logSegmentBytes, "logSegmentBytes");
        Utils.checkNotNull(logCleanupAndCompaction, "logCleanupAndCompaction");
        Utils.checkNotNull(offsetsRetentionMinutes, "offsetsRetentionMinutes");
        Utils.checkNotNull(logRetentionMs, "logRetentionMs");
        this.saslOauthbearerExpectedAudience = saslOauthbearerExpectedAudience;
        this.groupMaxSessionTimeoutMs = groupMaxSessionTimeoutMs;
        this.logFlushIntervalMessages = logFlushIntervalMessages;
        this.saslOauthbearerJwksEndpointUrl = saslOauthbearerJwksEndpointUrl;
        this.maxConnectionsPerIp = maxConnectionsPerIp;
        this.saslOauthbearerExpectedIssuer = saslOauthbearerExpectedIssuer;
        this.logIndexSizeMaxBytes = logIndexSizeMaxBytes;
        this.autoCreateTopicsEnable = autoCreateTopicsEnable;
        this.logIndexIntervalBytes = logIndexIntervalBytes;
        this.replicaFetchMaxBytes = replicaFetchMaxBytes;
        this.numPartitions = numPartitions;
        this.transactionStateLogSegmentBytes = transactionStateLogSegmentBytes;
        this.replicaFetchResponseMaxBytes = replicaFetchResponseMaxBytes;
        this.logMessageTimestampType = logMessageTimestampType;
        this.connectionsMaxIdleMs = connectionsMaxIdleMs;
        this.logFlushIntervalMs = logFlushIntervalMs;
        this.logPreallocate = logPreallocate;
        this.logSegmentDeleteDelayMs = logSegmentDeleteDelayMs;
        this.messageMaxBytes = messageMaxBytes;
        this.groupInitialRebalanceDelayMs = groupInitialRebalanceDelayMs;
        this.logLocalRetentionBytes = logLocalRetentionBytes;
        this.logRollJitterMs = logRollJitterMs;
        this.transactionRemoveExpiredTransactionCleanupIntervalMs = transactionRemoveExpiredTransactionCleanupIntervalMs;
        this.defaultReplicationFactor = defaultReplicationFactor;
        this.logRollMs = logRollMs;
        this.producerPurgatoryPurgeIntervalRequests = producerPurgatoryPurgeIntervalRequests;
        this.logRetentionBytes = logRetentionBytes;
        this.minInsyncReplicas = minInsyncReplicas;
        this.compressionType = compressionType;
        this.logMessageTimestampDifferenceMaxMs = logMessageTimestampDifferenceMaxMs;
        this.logLocalRetentionMs = logLocalRetentionMs;
        this.logMessageDownconversionEnable = logMessageDownconversionEnable;
        this.saslOauthbearerSubClaimName = saslOauthbearerSubClaimName;
        this.maxIncrementalFetchSessionCacheSlots = maxIncrementalFetchSessionCacheSlots;
        this.logRetentionHours = logRetentionHours;
        this.groupMinSessionTimeoutMs = groupMinSessionTimeoutMs;
        this.socketRequestMaxBytes = socketRequestMaxBytes;
        this.logSegmentBytes = logSegmentBytes;
        this.logCleanupAndCompaction = logCleanupAndCompaction;
        this.offsetsRetentionMinutes = offsetsRetentionMinutes;
        this.logRetentionMs = logRetentionMs;
    }

    /**
     * The (optional) comma-delimited setting for the broker to use to verify that the JWT was issued for one of the expected audiences.
     */
    public Optional<? extends String> saslOauthbearerExpectedAudience() {
        return saslOauthbearerExpectedAudience;
    }

    /**
     * The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    public Optional<? extends Long> groupMaxSessionTimeoutMs() {
        return groupMaxSessionTimeoutMs;
    }

    /**
     * The number of messages accumulated on a log partition before messages are flushed to disk
     */
    public Optional<? extends Long> logFlushIntervalMessages() {
        return logFlushIntervalMessages;
    }

    /**
     * OIDC JWKS endpoint URL. By setting this the SASL SSL OAuth2/OIDC authentication is enabled. See also other options for SASL OAuth2/OIDC. 
     */
    public Optional<? extends String> saslOauthbearerJwksEndpointUrl() {
        return saslOauthbearerJwksEndpointUrl;
    }

    /**
     * The maximum number of connections allowed from each ip address (defaults to 2147483647).
     */
    public Optional<? extends Long> maxConnectionsPerIp() {
        return maxConnectionsPerIp;
    }

    /**
     * Optional setting for the broker to use to verify that the JWT was created by the expected issuer.
     */
    public Optional<? extends String> saslOauthbearerExpectedIssuer() {
        return saslOauthbearerExpectedIssuer;
    }

    /**
     * The maximum size in bytes of the offset index
     */
    public Optional<? extends Long> logIndexSizeMaxBytes() {
        return logIndexSizeMaxBytes;
    }

    /**
     * Enable auto creation of topics
     */
    public Optional<? extends Boolean> autoCreateTopicsEnable() {
        return autoCreateTopicsEnable;
    }

    /**
     * The interval with which Kafka adds an entry to the offset index
     */
    public Optional<? extends Long> logIndexIntervalBytes() {
        return logIndexIntervalBytes;
    }

    /**
     * The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
     */
    public Optional<? extends Long> replicaFetchMaxBytes() {
        return replicaFetchMaxBytes;
    }

    /**
     * Number of partitions for autocreated topics
     */
    public Optional<? extends Long> numPartitions() {
        return numPartitions;
    }

    /**
     * The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).
     */
    public Optional<? extends Long> transactionStateLogSegmentBytes() {
        return transactionStateLogSegmentBytes;
    }

    /**
     * Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
     */
    public Optional<? extends Long> replicaFetchResponseMaxBytes() {
        return replicaFetchResponseMaxBytes;
    }

    /**
     * Define whether the timestamp in the message is message create time or log append time.
     */
    public Optional<? extends LogMessageTimestampType> logMessageTimestampType() {
        return logMessageTimestampType;
    }

    /**
     * Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.
     */
    public Optional<? extends Long> connectionsMaxIdleMs() {
        return connectionsMaxIdleMs;
    }

    /**
     * The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
     */
    public Optional<? extends Long> logFlushIntervalMs() {
        return logFlushIntervalMs;
    }

    /**
     * Should pre allocate file when create new segment?
     */
    public Optional<? extends Boolean> logPreallocate() {
        return logPreallocate;
    }

    /**
     * The amount of time to wait before deleting a file from the filesystem
     */
    public Optional<? extends Long> logSegmentDeleteDelayMs() {
        return logSegmentDeleteDelayMs;
    }

    /**
     * The maximum size of message that the server can receive.
     */
    public Optional<? extends Long> messageMaxBytes() {
        return messageMaxBytes;
    }

    /**
     * The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
     */
    public Optional<? extends Long> groupInitialRebalanceDelayMs() {
        return groupInitialRebalanceDelayMs;
    }

    /**
     * The maximum size of local log segments that can grow for a partition before it gets eligible for deletion. If set to -2, the value of log.retention.bytes is used. The effective value should always be less than or equal to log.retention.bytes value.
     */
    public Optional<? extends Long> logLocalRetentionBytes() {
        return logLocalRetentionBytes;
    }

    /**
     * The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
     */
    public Optional<? extends Long> logRollJitterMs() {
        return logRollJitterMs;
    }

    /**
     * The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).
     */
    public Optional<? extends Long> transactionRemoveExpiredTransactionCleanupIntervalMs() {
        return transactionRemoveExpiredTransactionCleanupIntervalMs;
    }

    /**
     * Replication factor for autocreated topics
     */
    public Optional<? extends Long> defaultReplicationFactor() {
        return defaultReplicationFactor;
    }

    /**
     * The maximum time before a new log segment is rolled out (in milliseconds).
     */
    public Optional<? extends Long> logRollMs() {
        return logRollMs;
    }

    /**
     * The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
     */
    public Optional<? extends Long> producerPurgatoryPurgeIntervalRequests() {
        return producerPurgatoryPurgeIntervalRequests;
    }

    /**
     * The maximum size of the log before deleting messages
     */
    public Optional<? extends Long> logRetentionBytes() {
        return logRetentionBytes;
    }

    /**
     * When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
     */
    public Optional<? extends Long> minInsyncReplicas() {
        return minInsyncReplicas;
    }

    /**
     * Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
     */
    public Optional<? extends CompressionType> compressionType() {
        return compressionType;
    }

    /**
     * The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
     */
    public Optional<? extends Long> logMessageTimestampDifferenceMaxMs() {
        return logMessageTimestampDifferenceMaxMs;
    }

    /**
     * The number of milliseconds to keep the local log segments before it gets eligible for deletion. If set to -2, the value of log.retention.ms is used. The effective value should always be less than or equal to log.retention.ms value.
     */
    public Optional<? extends Long> logLocalRetentionMs() {
        return logLocalRetentionMs;
    }

    /**
     * This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. 
     */
    public Optional<? extends Boolean> logMessageDownconversionEnable() {
        return logMessageDownconversionEnable;
    }

    /**
     * Name of the scope from which to extract the subject claim from the JWT. Defaults to sub.
     */
    public Optional<? extends String> saslOauthbearerSubClaimName() {
        return saslOauthbearerSubClaimName;
    }

    /**
     * The maximum number of incremental fetch sessions that the broker will maintain.
     */
    public Optional<? extends Long> maxIncrementalFetchSessionCacheSlots() {
        return maxIncrementalFetchSessionCacheSlots;
    }

    /**
     * The number of hours to keep a log file before deleting it
     */
    public Optional<? extends Long> logRetentionHours() {
        return logRetentionHours;
    }

    /**
     * The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    public Optional<? extends Long> groupMinSessionTimeoutMs() {
        return groupMinSessionTimeoutMs;
    }

    /**
     * The maximum number of bytes in a socket request (defaults to 104857600).
     */
    public Optional<? extends Long> socketRequestMaxBytes() {
        return socketRequestMaxBytes;
    }

    /**
     * The maximum size of a single log file
     */
    public Optional<? extends Long> logSegmentBytes() {
        return logSegmentBytes;
    }

    public Optional<? extends ConfigureLogCleanerForTopicCompaction> logCleanupAndCompaction() {
        return logCleanupAndCompaction;
    }

    /**
     * Log retention window in minutes for offsets topic
     */
    public Optional<? extends Long> offsetsRetentionMinutes() {
        return offsetsRetentionMinutes;
    }

    /**
     * The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
     */
    public Optional<? extends Long> logRetentionMs() {
        return logRetentionMs;
    }

    public final static Builder builder() {
        return new Builder();
    }

    /**
     * The (optional) comma-delimited setting for the broker to use to verify that the JWT was issued for one of the expected audiences.
     */
    public JsonSchemaKafka withSaslOauthbearerExpectedAudience(String saslOauthbearerExpectedAudience) {
        Utils.checkNotNull(saslOauthbearerExpectedAudience, "saslOauthbearerExpectedAudience");
        this.saslOauthbearerExpectedAudience = Optional.ofNullable(saslOauthbearerExpectedAudience);
        return this;
    }

    /**
     * The (optional) comma-delimited setting for the broker to use to verify that the JWT was issued for one of the expected audiences.
     */
    public JsonSchemaKafka withSaslOauthbearerExpectedAudience(Optional<? extends String> saslOauthbearerExpectedAudience) {
        Utils.checkNotNull(saslOauthbearerExpectedAudience, "saslOauthbearerExpectedAudience");
        this.saslOauthbearerExpectedAudience = saslOauthbearerExpectedAudience;
        return this;
    }

    /**
     * The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    public JsonSchemaKafka withGroupMaxSessionTimeoutMs(long groupMaxSessionTimeoutMs) {
        Utils.checkNotNull(groupMaxSessionTimeoutMs, "groupMaxSessionTimeoutMs");
        this.groupMaxSessionTimeoutMs = Optional.ofNullable(groupMaxSessionTimeoutMs);
        return this;
    }

    /**
     * The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    public JsonSchemaKafka withGroupMaxSessionTimeoutMs(Optional<? extends Long> groupMaxSessionTimeoutMs) {
        Utils.checkNotNull(groupMaxSessionTimeoutMs, "groupMaxSessionTimeoutMs");
        this.groupMaxSessionTimeoutMs = groupMaxSessionTimeoutMs;
        return this;
    }

    /**
     * The number of messages accumulated on a log partition before messages are flushed to disk
     */
    public JsonSchemaKafka withLogFlushIntervalMessages(long logFlushIntervalMessages) {
        Utils.checkNotNull(logFlushIntervalMessages, "logFlushIntervalMessages");
        this.logFlushIntervalMessages = Optional.ofNullable(logFlushIntervalMessages);
        return this;
    }

    /**
     * The number of messages accumulated on a log partition before messages are flushed to disk
     */
    public JsonSchemaKafka withLogFlushIntervalMessages(Optional<? extends Long> logFlushIntervalMessages) {
        Utils.checkNotNull(logFlushIntervalMessages, "logFlushIntervalMessages");
        this.logFlushIntervalMessages = logFlushIntervalMessages;
        return this;
    }

    /**
     * OIDC JWKS endpoint URL. By setting this the SASL SSL OAuth2/OIDC authentication is enabled. See also other options for SASL OAuth2/OIDC. 
     */
    public JsonSchemaKafka withSaslOauthbearerJwksEndpointUrl(String saslOauthbearerJwksEndpointUrl) {
        Utils.checkNotNull(saslOauthbearerJwksEndpointUrl, "saslOauthbearerJwksEndpointUrl");
        this.saslOauthbearerJwksEndpointUrl = Optional.ofNullable(saslOauthbearerJwksEndpointUrl);
        return this;
    }

    /**
     * OIDC JWKS endpoint URL. By setting this the SASL SSL OAuth2/OIDC authentication is enabled. See also other options for SASL OAuth2/OIDC. 
     */
    public JsonSchemaKafka withSaslOauthbearerJwksEndpointUrl(Optional<? extends String> saslOauthbearerJwksEndpointUrl) {
        Utils.checkNotNull(saslOauthbearerJwksEndpointUrl, "saslOauthbearerJwksEndpointUrl");
        this.saslOauthbearerJwksEndpointUrl = saslOauthbearerJwksEndpointUrl;
        return this;
    }

    /**
     * The maximum number of connections allowed from each ip address (defaults to 2147483647).
     */
    public JsonSchemaKafka withMaxConnectionsPerIp(long maxConnectionsPerIp) {
        Utils.checkNotNull(maxConnectionsPerIp, "maxConnectionsPerIp");
        this.maxConnectionsPerIp = Optional.ofNullable(maxConnectionsPerIp);
        return this;
    }

    /**
     * The maximum number of connections allowed from each ip address (defaults to 2147483647).
     */
    public JsonSchemaKafka withMaxConnectionsPerIp(Optional<? extends Long> maxConnectionsPerIp) {
        Utils.checkNotNull(maxConnectionsPerIp, "maxConnectionsPerIp");
        this.maxConnectionsPerIp = maxConnectionsPerIp;
        return this;
    }

    /**
     * Optional setting for the broker to use to verify that the JWT was created by the expected issuer.
     */
    public JsonSchemaKafka withSaslOauthbearerExpectedIssuer(String saslOauthbearerExpectedIssuer) {
        Utils.checkNotNull(saslOauthbearerExpectedIssuer, "saslOauthbearerExpectedIssuer");
        this.saslOauthbearerExpectedIssuer = Optional.ofNullable(saslOauthbearerExpectedIssuer);
        return this;
    }

    /**
     * Optional setting for the broker to use to verify that the JWT was created by the expected issuer.
     */
    public JsonSchemaKafka withSaslOauthbearerExpectedIssuer(Optional<? extends String> saslOauthbearerExpectedIssuer) {
        Utils.checkNotNull(saslOauthbearerExpectedIssuer, "saslOauthbearerExpectedIssuer");
        this.saslOauthbearerExpectedIssuer = saslOauthbearerExpectedIssuer;
        return this;
    }

    /**
     * The maximum size in bytes of the offset index
     */
    public JsonSchemaKafka withLogIndexSizeMaxBytes(long logIndexSizeMaxBytes) {
        Utils.checkNotNull(logIndexSizeMaxBytes, "logIndexSizeMaxBytes");
        this.logIndexSizeMaxBytes = Optional.ofNullable(logIndexSizeMaxBytes);
        return this;
    }

    /**
     * The maximum size in bytes of the offset index
     */
    public JsonSchemaKafka withLogIndexSizeMaxBytes(Optional<? extends Long> logIndexSizeMaxBytes) {
        Utils.checkNotNull(logIndexSizeMaxBytes, "logIndexSizeMaxBytes");
        this.logIndexSizeMaxBytes = logIndexSizeMaxBytes;
        return this;
    }

    /**
     * Enable auto creation of topics
     */
    public JsonSchemaKafka withAutoCreateTopicsEnable(boolean autoCreateTopicsEnable) {
        Utils.checkNotNull(autoCreateTopicsEnable, "autoCreateTopicsEnable");
        this.autoCreateTopicsEnable = Optional.ofNullable(autoCreateTopicsEnable);
        return this;
    }

    /**
     * Enable auto creation of topics
     */
    public JsonSchemaKafka withAutoCreateTopicsEnable(Optional<? extends Boolean> autoCreateTopicsEnable) {
        Utils.checkNotNull(autoCreateTopicsEnable, "autoCreateTopicsEnable");
        this.autoCreateTopicsEnable = autoCreateTopicsEnable;
        return this;
    }

    /**
     * The interval with which Kafka adds an entry to the offset index
     */
    public JsonSchemaKafka withLogIndexIntervalBytes(long logIndexIntervalBytes) {
        Utils.checkNotNull(logIndexIntervalBytes, "logIndexIntervalBytes");
        this.logIndexIntervalBytes = Optional.ofNullable(logIndexIntervalBytes);
        return this;
    }

    /**
     * The interval with which Kafka adds an entry to the offset index
     */
    public JsonSchemaKafka withLogIndexIntervalBytes(Optional<? extends Long> logIndexIntervalBytes) {
        Utils.checkNotNull(logIndexIntervalBytes, "logIndexIntervalBytes");
        this.logIndexIntervalBytes = logIndexIntervalBytes;
        return this;
    }

    /**
     * The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
     */
    public JsonSchemaKafka withReplicaFetchMaxBytes(long replicaFetchMaxBytes) {
        Utils.checkNotNull(replicaFetchMaxBytes, "replicaFetchMaxBytes");
        this.replicaFetchMaxBytes = Optional.ofNullable(replicaFetchMaxBytes);
        return this;
    }

    /**
     * The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
     */
    public JsonSchemaKafka withReplicaFetchMaxBytes(Optional<? extends Long> replicaFetchMaxBytes) {
        Utils.checkNotNull(replicaFetchMaxBytes, "replicaFetchMaxBytes");
        this.replicaFetchMaxBytes = replicaFetchMaxBytes;
        return this;
    }

    /**
     * Number of partitions for autocreated topics
     */
    public JsonSchemaKafka withNumPartitions(long numPartitions) {
        Utils.checkNotNull(numPartitions, "numPartitions");
        this.numPartitions = Optional.ofNullable(numPartitions);
        return this;
    }

    /**
     * Number of partitions for autocreated topics
     */
    public JsonSchemaKafka withNumPartitions(Optional<? extends Long> numPartitions) {
        Utils.checkNotNull(numPartitions, "numPartitions");
        this.numPartitions = numPartitions;
        return this;
    }

    /**
     * The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).
     */
    public JsonSchemaKafka withTransactionStateLogSegmentBytes(long transactionStateLogSegmentBytes) {
        Utils.checkNotNull(transactionStateLogSegmentBytes, "transactionStateLogSegmentBytes");
        this.transactionStateLogSegmentBytes = Optional.ofNullable(transactionStateLogSegmentBytes);
        return this;
    }

    /**
     * The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).
     */
    public JsonSchemaKafka withTransactionStateLogSegmentBytes(Optional<? extends Long> transactionStateLogSegmentBytes) {
        Utils.checkNotNull(transactionStateLogSegmentBytes, "transactionStateLogSegmentBytes");
        this.transactionStateLogSegmentBytes = transactionStateLogSegmentBytes;
        return this;
    }

    /**
     * Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
     */
    public JsonSchemaKafka withReplicaFetchResponseMaxBytes(long replicaFetchResponseMaxBytes) {
        Utils.checkNotNull(replicaFetchResponseMaxBytes, "replicaFetchResponseMaxBytes");
        this.replicaFetchResponseMaxBytes = Optional.ofNullable(replicaFetchResponseMaxBytes);
        return this;
    }

    /**
     * Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
     */
    public JsonSchemaKafka withReplicaFetchResponseMaxBytes(Optional<? extends Long> replicaFetchResponseMaxBytes) {
        Utils.checkNotNull(replicaFetchResponseMaxBytes, "replicaFetchResponseMaxBytes");
        this.replicaFetchResponseMaxBytes = replicaFetchResponseMaxBytes;
        return this;
    }

    /**
     * Define whether the timestamp in the message is message create time or log append time.
     */
    public JsonSchemaKafka withLogMessageTimestampType(LogMessageTimestampType logMessageTimestampType) {
        Utils.checkNotNull(logMessageTimestampType, "logMessageTimestampType");
        this.logMessageTimestampType = Optional.ofNullable(logMessageTimestampType);
        return this;
    }

    /**
     * Define whether the timestamp in the message is message create time or log append time.
     */
    public JsonSchemaKafka withLogMessageTimestampType(Optional<? extends LogMessageTimestampType> logMessageTimestampType) {
        Utils.checkNotNull(logMessageTimestampType, "logMessageTimestampType");
        this.logMessageTimestampType = logMessageTimestampType;
        return this;
    }

    /**
     * Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.
     */
    public JsonSchemaKafka withConnectionsMaxIdleMs(long connectionsMaxIdleMs) {
        Utils.checkNotNull(connectionsMaxIdleMs, "connectionsMaxIdleMs");
        this.connectionsMaxIdleMs = Optional.ofNullable(connectionsMaxIdleMs);
        return this;
    }

    /**
     * Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.
     */
    public JsonSchemaKafka withConnectionsMaxIdleMs(Optional<? extends Long> connectionsMaxIdleMs) {
        Utils.checkNotNull(connectionsMaxIdleMs, "connectionsMaxIdleMs");
        this.connectionsMaxIdleMs = connectionsMaxIdleMs;
        return this;
    }

    /**
     * The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
     */
    public JsonSchemaKafka withLogFlushIntervalMs(long logFlushIntervalMs) {
        Utils.checkNotNull(logFlushIntervalMs, "logFlushIntervalMs");
        this.logFlushIntervalMs = Optional.ofNullable(logFlushIntervalMs);
        return this;
    }

    /**
     * The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
     */
    public JsonSchemaKafka withLogFlushIntervalMs(Optional<? extends Long> logFlushIntervalMs) {
        Utils.checkNotNull(logFlushIntervalMs, "logFlushIntervalMs");
        this.logFlushIntervalMs = logFlushIntervalMs;
        return this;
    }

    /**
     * Should pre allocate file when create new segment?
     */
    public JsonSchemaKafka withLogPreallocate(boolean logPreallocate) {
        Utils.checkNotNull(logPreallocate, "logPreallocate");
        this.logPreallocate = Optional.ofNullable(logPreallocate);
        return this;
    }

    /**
     * Should pre allocate file when create new segment?
     */
    public JsonSchemaKafka withLogPreallocate(Optional<? extends Boolean> logPreallocate) {
        Utils.checkNotNull(logPreallocate, "logPreallocate");
        this.logPreallocate = logPreallocate;
        return this;
    }

    /**
     * The amount of time to wait before deleting a file from the filesystem
     */
    public JsonSchemaKafka withLogSegmentDeleteDelayMs(long logSegmentDeleteDelayMs) {
        Utils.checkNotNull(logSegmentDeleteDelayMs, "logSegmentDeleteDelayMs");
        this.logSegmentDeleteDelayMs = Optional.ofNullable(logSegmentDeleteDelayMs);
        return this;
    }

    /**
     * The amount of time to wait before deleting a file from the filesystem
     */
    public JsonSchemaKafka withLogSegmentDeleteDelayMs(Optional<? extends Long> logSegmentDeleteDelayMs) {
        Utils.checkNotNull(logSegmentDeleteDelayMs, "logSegmentDeleteDelayMs");
        this.logSegmentDeleteDelayMs = logSegmentDeleteDelayMs;
        return this;
    }

    /**
     * The maximum size of message that the server can receive.
     */
    public JsonSchemaKafka withMessageMaxBytes(long messageMaxBytes) {
        Utils.checkNotNull(messageMaxBytes, "messageMaxBytes");
        this.messageMaxBytes = Optional.ofNullable(messageMaxBytes);
        return this;
    }

    /**
     * The maximum size of message that the server can receive.
     */
    public JsonSchemaKafka withMessageMaxBytes(Optional<? extends Long> messageMaxBytes) {
        Utils.checkNotNull(messageMaxBytes, "messageMaxBytes");
        this.messageMaxBytes = messageMaxBytes;
        return this;
    }

    /**
     * The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
     */
    public JsonSchemaKafka withGroupInitialRebalanceDelayMs(long groupInitialRebalanceDelayMs) {
        Utils.checkNotNull(groupInitialRebalanceDelayMs, "groupInitialRebalanceDelayMs");
        this.groupInitialRebalanceDelayMs = Optional.ofNullable(groupInitialRebalanceDelayMs);
        return this;
    }

    /**
     * The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
     */
    public JsonSchemaKafka withGroupInitialRebalanceDelayMs(Optional<? extends Long> groupInitialRebalanceDelayMs) {
        Utils.checkNotNull(groupInitialRebalanceDelayMs, "groupInitialRebalanceDelayMs");
        this.groupInitialRebalanceDelayMs = groupInitialRebalanceDelayMs;
        return this;
    }

    /**
     * The maximum size of local log segments that can grow for a partition before it gets eligible for deletion. If set to -2, the value of log.retention.bytes is used. The effective value should always be less than or equal to log.retention.bytes value.
     */
    public JsonSchemaKafka withLogLocalRetentionBytes(long logLocalRetentionBytes) {
        Utils.checkNotNull(logLocalRetentionBytes, "logLocalRetentionBytes");
        this.logLocalRetentionBytes = Optional.ofNullable(logLocalRetentionBytes);
        return this;
    }

    /**
     * The maximum size of local log segments that can grow for a partition before it gets eligible for deletion. If set to -2, the value of log.retention.bytes is used. The effective value should always be less than or equal to log.retention.bytes value.
     */
    public JsonSchemaKafka withLogLocalRetentionBytes(Optional<? extends Long> logLocalRetentionBytes) {
        Utils.checkNotNull(logLocalRetentionBytes, "logLocalRetentionBytes");
        this.logLocalRetentionBytes = logLocalRetentionBytes;
        return this;
    }

    /**
     * The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
     */
    public JsonSchemaKafka withLogRollJitterMs(long logRollJitterMs) {
        Utils.checkNotNull(logRollJitterMs, "logRollJitterMs");
        this.logRollJitterMs = Optional.ofNullable(logRollJitterMs);
        return this;
    }

    /**
     * The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
     */
    public JsonSchemaKafka withLogRollJitterMs(Optional<? extends Long> logRollJitterMs) {
        Utils.checkNotNull(logRollJitterMs, "logRollJitterMs");
        this.logRollJitterMs = logRollJitterMs;
        return this;
    }

    /**
     * The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).
     */
    public JsonSchemaKafka withTransactionRemoveExpiredTransactionCleanupIntervalMs(long transactionRemoveExpiredTransactionCleanupIntervalMs) {
        Utils.checkNotNull(transactionRemoveExpiredTransactionCleanupIntervalMs, "transactionRemoveExpiredTransactionCleanupIntervalMs");
        this.transactionRemoveExpiredTransactionCleanupIntervalMs = Optional.ofNullable(transactionRemoveExpiredTransactionCleanupIntervalMs);
        return this;
    }

    /**
     * The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).
     */
    public JsonSchemaKafka withTransactionRemoveExpiredTransactionCleanupIntervalMs(Optional<? extends Long> transactionRemoveExpiredTransactionCleanupIntervalMs) {
        Utils.checkNotNull(transactionRemoveExpiredTransactionCleanupIntervalMs, "transactionRemoveExpiredTransactionCleanupIntervalMs");
        this.transactionRemoveExpiredTransactionCleanupIntervalMs = transactionRemoveExpiredTransactionCleanupIntervalMs;
        return this;
    }

    /**
     * Replication factor for autocreated topics
     */
    public JsonSchemaKafka withDefaultReplicationFactor(long defaultReplicationFactor) {
        Utils.checkNotNull(defaultReplicationFactor, "defaultReplicationFactor");
        this.defaultReplicationFactor = Optional.ofNullable(defaultReplicationFactor);
        return this;
    }

    /**
     * Replication factor for autocreated topics
     */
    public JsonSchemaKafka withDefaultReplicationFactor(Optional<? extends Long> defaultReplicationFactor) {
        Utils.checkNotNull(defaultReplicationFactor, "defaultReplicationFactor");
        this.defaultReplicationFactor = defaultReplicationFactor;
        return this;
    }

    /**
     * The maximum time before a new log segment is rolled out (in milliseconds).
     */
    public JsonSchemaKafka withLogRollMs(long logRollMs) {
        Utils.checkNotNull(logRollMs, "logRollMs");
        this.logRollMs = Optional.ofNullable(logRollMs);
        return this;
    }

    /**
     * The maximum time before a new log segment is rolled out (in milliseconds).
     */
    public JsonSchemaKafka withLogRollMs(Optional<? extends Long> logRollMs) {
        Utils.checkNotNull(logRollMs, "logRollMs");
        this.logRollMs = logRollMs;
        return this;
    }

    /**
     * The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
     */
    public JsonSchemaKafka withProducerPurgatoryPurgeIntervalRequests(long producerPurgatoryPurgeIntervalRequests) {
        Utils.checkNotNull(producerPurgatoryPurgeIntervalRequests, "producerPurgatoryPurgeIntervalRequests");
        this.producerPurgatoryPurgeIntervalRequests = Optional.ofNullable(producerPurgatoryPurgeIntervalRequests);
        return this;
    }

    /**
     * The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
     */
    public JsonSchemaKafka withProducerPurgatoryPurgeIntervalRequests(Optional<? extends Long> producerPurgatoryPurgeIntervalRequests) {
        Utils.checkNotNull(producerPurgatoryPurgeIntervalRequests, "producerPurgatoryPurgeIntervalRequests");
        this.producerPurgatoryPurgeIntervalRequests = producerPurgatoryPurgeIntervalRequests;
        return this;
    }

    /**
     * The maximum size of the log before deleting messages
     */
    public JsonSchemaKafka withLogRetentionBytes(long logRetentionBytes) {
        Utils.checkNotNull(logRetentionBytes, "logRetentionBytes");
        this.logRetentionBytes = Optional.ofNullable(logRetentionBytes);
        return this;
    }

    /**
     * The maximum size of the log before deleting messages
     */
    public JsonSchemaKafka withLogRetentionBytes(Optional<? extends Long> logRetentionBytes) {
        Utils.checkNotNull(logRetentionBytes, "logRetentionBytes");
        this.logRetentionBytes = logRetentionBytes;
        return this;
    }

    /**
     * When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
     */
    public JsonSchemaKafka withMinInsyncReplicas(long minInsyncReplicas) {
        Utils.checkNotNull(minInsyncReplicas, "minInsyncReplicas");
        this.minInsyncReplicas = Optional.ofNullable(minInsyncReplicas);
        return this;
    }

    /**
     * When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
     */
    public JsonSchemaKafka withMinInsyncReplicas(Optional<? extends Long> minInsyncReplicas) {
        Utils.checkNotNull(minInsyncReplicas, "minInsyncReplicas");
        this.minInsyncReplicas = minInsyncReplicas;
        return this;
    }

    /**
     * Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
     */
    public JsonSchemaKafka withCompressionType(CompressionType compressionType) {
        Utils.checkNotNull(compressionType, "compressionType");
        this.compressionType = Optional.ofNullable(compressionType);
        return this;
    }

    /**
     * Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
     */
    public JsonSchemaKafka withCompressionType(Optional<? extends CompressionType> compressionType) {
        Utils.checkNotNull(compressionType, "compressionType");
        this.compressionType = compressionType;
        return this;
    }

    /**
     * The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
     */
    public JsonSchemaKafka withLogMessageTimestampDifferenceMaxMs(long logMessageTimestampDifferenceMaxMs) {
        Utils.checkNotNull(logMessageTimestampDifferenceMaxMs, "logMessageTimestampDifferenceMaxMs");
        this.logMessageTimestampDifferenceMaxMs = Optional.ofNullable(logMessageTimestampDifferenceMaxMs);
        return this;
    }

    /**
     * The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
     */
    public JsonSchemaKafka withLogMessageTimestampDifferenceMaxMs(Optional<? extends Long> logMessageTimestampDifferenceMaxMs) {
        Utils.checkNotNull(logMessageTimestampDifferenceMaxMs, "logMessageTimestampDifferenceMaxMs");
        this.logMessageTimestampDifferenceMaxMs = logMessageTimestampDifferenceMaxMs;
        return this;
    }

    /**
     * The number of milliseconds to keep the local log segments before it gets eligible for deletion. If set to -2, the value of log.retention.ms is used. The effective value should always be less than or equal to log.retention.ms value.
     */
    public JsonSchemaKafka withLogLocalRetentionMs(long logLocalRetentionMs) {
        Utils.checkNotNull(logLocalRetentionMs, "logLocalRetentionMs");
        this.logLocalRetentionMs = Optional.ofNullable(logLocalRetentionMs);
        return this;
    }

    /**
     * The number of milliseconds to keep the local log segments before it gets eligible for deletion. If set to -2, the value of log.retention.ms is used. The effective value should always be less than or equal to log.retention.ms value.
     */
    public JsonSchemaKafka withLogLocalRetentionMs(Optional<? extends Long> logLocalRetentionMs) {
        Utils.checkNotNull(logLocalRetentionMs, "logLocalRetentionMs");
        this.logLocalRetentionMs = logLocalRetentionMs;
        return this;
    }

    /**
     * This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. 
     */
    public JsonSchemaKafka withLogMessageDownconversionEnable(boolean logMessageDownconversionEnable) {
        Utils.checkNotNull(logMessageDownconversionEnable, "logMessageDownconversionEnable");
        this.logMessageDownconversionEnable = Optional.ofNullable(logMessageDownconversionEnable);
        return this;
    }

    /**
     * This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. 
     */
    public JsonSchemaKafka withLogMessageDownconversionEnable(Optional<? extends Boolean> logMessageDownconversionEnable) {
        Utils.checkNotNull(logMessageDownconversionEnable, "logMessageDownconversionEnable");
        this.logMessageDownconversionEnable = logMessageDownconversionEnable;
        return this;
    }

    /**
     * Name of the scope from which to extract the subject claim from the JWT. Defaults to sub.
     */
    public JsonSchemaKafka withSaslOauthbearerSubClaimName(String saslOauthbearerSubClaimName) {
        Utils.checkNotNull(saslOauthbearerSubClaimName, "saslOauthbearerSubClaimName");
        this.saslOauthbearerSubClaimName = Optional.ofNullable(saslOauthbearerSubClaimName);
        return this;
    }

    /**
     * Name of the scope from which to extract the subject claim from the JWT. Defaults to sub.
     */
    public JsonSchemaKafka withSaslOauthbearerSubClaimName(Optional<? extends String> saslOauthbearerSubClaimName) {
        Utils.checkNotNull(saslOauthbearerSubClaimName, "saslOauthbearerSubClaimName");
        this.saslOauthbearerSubClaimName = saslOauthbearerSubClaimName;
        return this;
    }

    /**
     * The maximum number of incremental fetch sessions that the broker will maintain.
     */
    public JsonSchemaKafka withMaxIncrementalFetchSessionCacheSlots(long maxIncrementalFetchSessionCacheSlots) {
        Utils.checkNotNull(maxIncrementalFetchSessionCacheSlots, "maxIncrementalFetchSessionCacheSlots");
        this.maxIncrementalFetchSessionCacheSlots = Optional.ofNullable(maxIncrementalFetchSessionCacheSlots);
        return this;
    }

    /**
     * The maximum number of incremental fetch sessions that the broker will maintain.
     */
    public JsonSchemaKafka withMaxIncrementalFetchSessionCacheSlots(Optional<? extends Long> maxIncrementalFetchSessionCacheSlots) {
        Utils.checkNotNull(maxIncrementalFetchSessionCacheSlots, "maxIncrementalFetchSessionCacheSlots");
        this.maxIncrementalFetchSessionCacheSlots = maxIncrementalFetchSessionCacheSlots;
        return this;
    }

    /**
     * The number of hours to keep a log file before deleting it
     */
    public JsonSchemaKafka withLogRetentionHours(long logRetentionHours) {
        Utils.checkNotNull(logRetentionHours, "logRetentionHours");
        this.logRetentionHours = Optional.ofNullable(logRetentionHours);
        return this;
    }

    /**
     * The number of hours to keep a log file before deleting it
     */
    public JsonSchemaKafka withLogRetentionHours(Optional<? extends Long> logRetentionHours) {
        Utils.checkNotNull(logRetentionHours, "logRetentionHours");
        this.logRetentionHours = logRetentionHours;
        return this;
    }

    /**
     * The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    public JsonSchemaKafka withGroupMinSessionTimeoutMs(long groupMinSessionTimeoutMs) {
        Utils.checkNotNull(groupMinSessionTimeoutMs, "groupMinSessionTimeoutMs");
        this.groupMinSessionTimeoutMs = Optional.ofNullable(groupMinSessionTimeoutMs);
        return this;
    }

    /**
     * The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
     */
    public JsonSchemaKafka withGroupMinSessionTimeoutMs(Optional<? extends Long> groupMinSessionTimeoutMs) {
        Utils.checkNotNull(groupMinSessionTimeoutMs, "groupMinSessionTimeoutMs");
        this.groupMinSessionTimeoutMs = groupMinSessionTimeoutMs;
        return this;
    }

    /**
     * The maximum number of bytes in a socket request (defaults to 104857600).
     */
    public JsonSchemaKafka withSocketRequestMaxBytes(long socketRequestMaxBytes) {
        Utils.checkNotNull(socketRequestMaxBytes, "socketRequestMaxBytes");
        this.socketRequestMaxBytes = Optional.ofNullable(socketRequestMaxBytes);
        return this;
    }

    /**
     * The maximum number of bytes in a socket request (defaults to 104857600).
     */
    public JsonSchemaKafka withSocketRequestMaxBytes(Optional<? extends Long> socketRequestMaxBytes) {
        Utils.checkNotNull(socketRequestMaxBytes, "socketRequestMaxBytes");
        this.socketRequestMaxBytes = socketRequestMaxBytes;
        return this;
    }

    /**
     * The maximum size of a single log file
     */
    public JsonSchemaKafka withLogSegmentBytes(long logSegmentBytes) {
        Utils.checkNotNull(logSegmentBytes, "logSegmentBytes");
        this.logSegmentBytes = Optional.ofNullable(logSegmentBytes);
        return this;
    }

    /**
     * The maximum size of a single log file
     */
    public JsonSchemaKafka withLogSegmentBytes(Optional<? extends Long> logSegmentBytes) {
        Utils.checkNotNull(logSegmentBytes, "logSegmentBytes");
        this.logSegmentBytes = logSegmentBytes;
        return this;
    }

    public JsonSchemaKafka withLogCleanupAndCompaction(ConfigureLogCleanerForTopicCompaction logCleanupAndCompaction) {
        Utils.checkNotNull(logCleanupAndCompaction, "logCleanupAndCompaction");
        this.logCleanupAndCompaction = Optional.ofNullable(logCleanupAndCompaction);
        return this;
    }

    public JsonSchemaKafka withLogCleanupAndCompaction(Optional<? extends ConfigureLogCleanerForTopicCompaction> logCleanupAndCompaction) {
        Utils.checkNotNull(logCleanupAndCompaction, "logCleanupAndCompaction");
        this.logCleanupAndCompaction = logCleanupAndCompaction;
        return this;
    }

    /**
     * Log retention window in minutes for offsets topic
     */
    public JsonSchemaKafka withOffsetsRetentionMinutes(long offsetsRetentionMinutes) {
        Utils.checkNotNull(offsetsRetentionMinutes, "offsetsRetentionMinutes");
        this.offsetsRetentionMinutes = Optional.ofNullable(offsetsRetentionMinutes);
        return this;
    }

    /**
     * Log retention window in minutes for offsets topic
     */
    public JsonSchemaKafka withOffsetsRetentionMinutes(Optional<? extends Long> offsetsRetentionMinutes) {
        Utils.checkNotNull(offsetsRetentionMinutes, "offsetsRetentionMinutes");
        this.offsetsRetentionMinutes = offsetsRetentionMinutes;
        return this;
    }

    /**
     * The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
     */
    public JsonSchemaKafka withLogRetentionMs(long logRetentionMs) {
        Utils.checkNotNull(logRetentionMs, "logRetentionMs");
        this.logRetentionMs = Optional.ofNullable(logRetentionMs);
        return this;
    }

    /**
     * The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
     */
    public JsonSchemaKafka withLogRetentionMs(Optional<? extends Long> logRetentionMs) {
        Utils.checkNotNull(logRetentionMs, "logRetentionMs");
        this.logRetentionMs = logRetentionMs;
        return this;
    }
    
    @Override
    public boolean equals(java.lang.Object o) {
        if (this == o) {
            return true;
        }
        if (o == null || getClass() != o.getClass()) {
            return false;
        }
        JsonSchemaKafka other = (JsonSchemaKafka) o;
        return 
            java.util.Objects.deepEquals(this.saslOauthbearerExpectedAudience, other.saslOauthbearerExpectedAudience) &&
            java.util.Objects.deepEquals(this.groupMaxSessionTimeoutMs, other.groupMaxSessionTimeoutMs) &&
            java.util.Objects.deepEquals(this.logFlushIntervalMessages, other.logFlushIntervalMessages) &&
            java.util.Objects.deepEquals(this.saslOauthbearerJwksEndpointUrl, other.saslOauthbearerJwksEndpointUrl) &&
            java.util.Objects.deepEquals(this.maxConnectionsPerIp, other.maxConnectionsPerIp) &&
            java.util.Objects.deepEquals(this.saslOauthbearerExpectedIssuer, other.saslOauthbearerExpectedIssuer) &&
            java.util.Objects.deepEquals(this.logIndexSizeMaxBytes, other.logIndexSizeMaxBytes) &&
            java.util.Objects.deepEquals(this.autoCreateTopicsEnable, other.autoCreateTopicsEnable) &&
            java.util.Objects.deepEquals(this.logIndexIntervalBytes, other.logIndexIntervalBytes) &&
            java.util.Objects.deepEquals(this.replicaFetchMaxBytes, other.replicaFetchMaxBytes) &&
            java.util.Objects.deepEquals(this.numPartitions, other.numPartitions) &&
            java.util.Objects.deepEquals(this.transactionStateLogSegmentBytes, other.transactionStateLogSegmentBytes) &&
            java.util.Objects.deepEquals(this.replicaFetchResponseMaxBytes, other.replicaFetchResponseMaxBytes) &&
            java.util.Objects.deepEquals(this.logMessageTimestampType, other.logMessageTimestampType) &&
            java.util.Objects.deepEquals(this.connectionsMaxIdleMs, other.connectionsMaxIdleMs) &&
            java.util.Objects.deepEquals(this.logFlushIntervalMs, other.logFlushIntervalMs) &&
            java.util.Objects.deepEquals(this.logPreallocate, other.logPreallocate) &&
            java.util.Objects.deepEquals(this.logSegmentDeleteDelayMs, other.logSegmentDeleteDelayMs) &&
            java.util.Objects.deepEquals(this.messageMaxBytes, other.messageMaxBytes) &&
            java.util.Objects.deepEquals(this.groupInitialRebalanceDelayMs, other.groupInitialRebalanceDelayMs) &&
            java.util.Objects.deepEquals(this.logLocalRetentionBytes, other.logLocalRetentionBytes) &&
            java.util.Objects.deepEquals(this.logRollJitterMs, other.logRollJitterMs) &&
            java.util.Objects.deepEquals(this.transactionRemoveExpiredTransactionCleanupIntervalMs, other.transactionRemoveExpiredTransactionCleanupIntervalMs) &&
            java.util.Objects.deepEquals(this.defaultReplicationFactor, other.defaultReplicationFactor) &&
            java.util.Objects.deepEquals(this.logRollMs, other.logRollMs) &&
            java.util.Objects.deepEquals(this.producerPurgatoryPurgeIntervalRequests, other.producerPurgatoryPurgeIntervalRequests) &&
            java.util.Objects.deepEquals(this.logRetentionBytes, other.logRetentionBytes) &&
            java.util.Objects.deepEquals(this.minInsyncReplicas, other.minInsyncReplicas) &&
            java.util.Objects.deepEquals(this.compressionType, other.compressionType) &&
            java.util.Objects.deepEquals(this.logMessageTimestampDifferenceMaxMs, other.logMessageTimestampDifferenceMaxMs) &&
            java.util.Objects.deepEquals(this.logLocalRetentionMs, other.logLocalRetentionMs) &&
            java.util.Objects.deepEquals(this.logMessageDownconversionEnable, other.logMessageDownconversionEnable) &&
            java.util.Objects.deepEquals(this.saslOauthbearerSubClaimName, other.saslOauthbearerSubClaimName) &&
            java.util.Objects.deepEquals(this.maxIncrementalFetchSessionCacheSlots, other.maxIncrementalFetchSessionCacheSlots) &&
            java.util.Objects.deepEquals(this.logRetentionHours, other.logRetentionHours) &&
            java.util.Objects.deepEquals(this.groupMinSessionTimeoutMs, other.groupMinSessionTimeoutMs) &&
            java.util.Objects.deepEquals(this.socketRequestMaxBytes, other.socketRequestMaxBytes) &&
            java.util.Objects.deepEquals(this.logSegmentBytes, other.logSegmentBytes) &&
            java.util.Objects.deepEquals(this.logCleanupAndCompaction, other.logCleanupAndCompaction) &&
            java.util.Objects.deepEquals(this.offsetsRetentionMinutes, other.offsetsRetentionMinutes) &&
            java.util.Objects.deepEquals(this.logRetentionMs, other.logRetentionMs);
    }
    
    @Override
    public int hashCode() {
        return java.util.Objects.hash(
            saslOauthbearerExpectedAudience,
            groupMaxSessionTimeoutMs,
            logFlushIntervalMessages,
            saslOauthbearerJwksEndpointUrl,
            maxConnectionsPerIp,
            saslOauthbearerExpectedIssuer,
            logIndexSizeMaxBytes,
            autoCreateTopicsEnable,
            logIndexIntervalBytes,
            replicaFetchMaxBytes,
            numPartitions,
            transactionStateLogSegmentBytes,
            replicaFetchResponseMaxBytes,
            logMessageTimestampType,
            connectionsMaxIdleMs,
            logFlushIntervalMs,
            logPreallocate,
            logSegmentDeleteDelayMs,
            messageMaxBytes,
            groupInitialRebalanceDelayMs,
            logLocalRetentionBytes,
            logRollJitterMs,
            transactionRemoveExpiredTransactionCleanupIntervalMs,
            defaultReplicationFactor,
            logRollMs,
            producerPurgatoryPurgeIntervalRequests,
            logRetentionBytes,
            minInsyncReplicas,
            compressionType,
            logMessageTimestampDifferenceMaxMs,
            logLocalRetentionMs,
            logMessageDownconversionEnable,
            saslOauthbearerSubClaimName,
            maxIncrementalFetchSessionCacheSlots,
            logRetentionHours,
            groupMinSessionTimeoutMs,
            socketRequestMaxBytes,
            logSegmentBytes,
            logCleanupAndCompaction,
            offsetsRetentionMinutes,
            logRetentionMs);
    }
    
    @Override
    public String toString() {
        return Utils.toString(JsonSchemaKafka.class,
                "saslOauthbearerExpectedAudience", saslOauthbearerExpectedAudience,
                "groupMaxSessionTimeoutMs", groupMaxSessionTimeoutMs,
                "logFlushIntervalMessages", logFlushIntervalMessages,
                "saslOauthbearerJwksEndpointUrl", saslOauthbearerJwksEndpointUrl,
                "maxConnectionsPerIp", maxConnectionsPerIp,
                "saslOauthbearerExpectedIssuer", saslOauthbearerExpectedIssuer,
                "logIndexSizeMaxBytes", logIndexSizeMaxBytes,
                "autoCreateTopicsEnable", autoCreateTopicsEnable,
                "logIndexIntervalBytes", logIndexIntervalBytes,
                "replicaFetchMaxBytes", replicaFetchMaxBytes,
                "numPartitions", numPartitions,
                "transactionStateLogSegmentBytes", transactionStateLogSegmentBytes,
                "replicaFetchResponseMaxBytes", replicaFetchResponseMaxBytes,
                "logMessageTimestampType", logMessageTimestampType,
                "connectionsMaxIdleMs", connectionsMaxIdleMs,
                "logFlushIntervalMs", logFlushIntervalMs,
                "logPreallocate", logPreallocate,
                "logSegmentDeleteDelayMs", logSegmentDeleteDelayMs,
                "messageMaxBytes", messageMaxBytes,
                "groupInitialRebalanceDelayMs", groupInitialRebalanceDelayMs,
                "logLocalRetentionBytes", logLocalRetentionBytes,
                "logRollJitterMs", logRollJitterMs,
                "transactionRemoveExpiredTransactionCleanupIntervalMs", transactionRemoveExpiredTransactionCleanupIntervalMs,
                "defaultReplicationFactor", defaultReplicationFactor,
                "logRollMs", logRollMs,
                "producerPurgatoryPurgeIntervalRequests", producerPurgatoryPurgeIntervalRequests,
                "logRetentionBytes", logRetentionBytes,
                "minInsyncReplicas", minInsyncReplicas,
                "compressionType", compressionType,
                "logMessageTimestampDifferenceMaxMs", logMessageTimestampDifferenceMaxMs,
                "logLocalRetentionMs", logLocalRetentionMs,
                "logMessageDownconversionEnable", logMessageDownconversionEnable,
                "saslOauthbearerSubClaimName", saslOauthbearerSubClaimName,
                "maxIncrementalFetchSessionCacheSlots", maxIncrementalFetchSessionCacheSlots,
                "logRetentionHours", logRetentionHours,
                "groupMinSessionTimeoutMs", groupMinSessionTimeoutMs,
                "socketRequestMaxBytes", socketRequestMaxBytes,
                "logSegmentBytes", logSegmentBytes,
                "logCleanupAndCompaction", logCleanupAndCompaction,
                "offsetsRetentionMinutes", offsetsRetentionMinutes,
                "logRetentionMs", logRetentionMs);
    }
    
    public final static class Builder {
 
        private Optional<? extends String> saslOauthbearerExpectedAudience = Optional.empty();
 
        private Optional<? extends Long> groupMaxSessionTimeoutMs = Optional.empty();
 
        private Optional<? extends Long> logFlushIntervalMessages = Optional.empty();
 
        private Optional<? extends String> saslOauthbearerJwksEndpointUrl = Optional.empty();
 
        private Optional<? extends Long> maxConnectionsPerIp = Optional.empty();
 
        private Optional<? extends String> saslOauthbearerExpectedIssuer = Optional.empty();
 
        private Optional<? extends Long> logIndexSizeMaxBytes = Optional.empty();
 
        private Optional<? extends Boolean> autoCreateTopicsEnable = Optional.empty();
 
        private Optional<? extends Long> logIndexIntervalBytes = Optional.empty();
 
        private Optional<? extends Long> replicaFetchMaxBytes = Optional.empty();
 
        private Optional<? extends Long> numPartitions = Optional.empty();
 
        private Optional<? extends Long> transactionStateLogSegmentBytes = Optional.empty();
 
        private Optional<? extends Long> replicaFetchResponseMaxBytes = Optional.empty();
 
        private Optional<? extends LogMessageTimestampType> logMessageTimestampType = Optional.empty();
 
        private Optional<? extends Long> connectionsMaxIdleMs = Optional.empty();
 
        private Optional<? extends Long> logFlushIntervalMs = Optional.empty();
 
        private Optional<? extends Boolean> logPreallocate = Optional.empty();
 
        private Optional<? extends Long> logSegmentDeleteDelayMs = Optional.empty();
 
        private Optional<? extends Long> messageMaxBytes = Optional.empty();
 
        private Optional<? extends Long> groupInitialRebalanceDelayMs = Optional.empty();
 
        private Optional<? extends Long> logLocalRetentionBytes = Optional.empty();
 
        private Optional<? extends Long> logRollJitterMs = Optional.empty();
 
        private Optional<? extends Long> transactionRemoveExpiredTransactionCleanupIntervalMs = Optional.empty();
 
        private Optional<? extends Long> defaultReplicationFactor = Optional.empty();
 
        private Optional<? extends Long> logRollMs = Optional.empty();
 
        private Optional<? extends Long> producerPurgatoryPurgeIntervalRequests = Optional.empty();
 
        private Optional<? extends Long> logRetentionBytes = Optional.empty();
 
        private Optional<? extends Long> minInsyncReplicas = Optional.empty();
 
        private Optional<? extends CompressionType> compressionType = Optional.empty();
 
        private Optional<? extends Long> logMessageTimestampDifferenceMaxMs = Optional.empty();
 
        private Optional<? extends Long> logLocalRetentionMs = Optional.empty();
 
        private Optional<? extends Boolean> logMessageDownconversionEnable = Optional.empty();
 
        private Optional<? extends String> saslOauthbearerSubClaimName = Optional.empty();
 
        private Optional<? extends Long> maxIncrementalFetchSessionCacheSlots = Optional.empty();
 
        private Optional<? extends Long> logRetentionHours = Optional.empty();
 
        private Optional<? extends Long> groupMinSessionTimeoutMs = Optional.empty();
 
        private Optional<? extends Long> socketRequestMaxBytes = Optional.empty();
 
        private Optional<? extends Long> logSegmentBytes = Optional.empty();
 
        private Optional<? extends ConfigureLogCleanerForTopicCompaction> logCleanupAndCompaction = Optional.empty();
 
        private Optional<? extends Long> offsetsRetentionMinutes = Optional.empty();
 
        private Optional<? extends Long> logRetentionMs = Optional.empty();  
        
        private Builder() {
          // force use of static builder() method
        }

        /**
         * The (optional) comma-delimited setting for the broker to use to verify that the JWT was issued for one of the expected audiences.
         */
        public Builder saslOauthbearerExpectedAudience(String saslOauthbearerExpectedAudience) {
            Utils.checkNotNull(saslOauthbearerExpectedAudience, "saslOauthbearerExpectedAudience");
            this.saslOauthbearerExpectedAudience = Optional.ofNullable(saslOauthbearerExpectedAudience);
            return this;
        }

        /**
         * The (optional) comma-delimited setting for the broker to use to verify that the JWT was issued for one of the expected audiences.
         */
        public Builder saslOauthbearerExpectedAudience(Optional<? extends String> saslOauthbearerExpectedAudience) {
            Utils.checkNotNull(saslOauthbearerExpectedAudience, "saslOauthbearerExpectedAudience");
            this.saslOauthbearerExpectedAudience = saslOauthbearerExpectedAudience;
            return this;
        }

        /**
         * The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
         */
        public Builder groupMaxSessionTimeoutMs(long groupMaxSessionTimeoutMs) {
            Utils.checkNotNull(groupMaxSessionTimeoutMs, "groupMaxSessionTimeoutMs");
            this.groupMaxSessionTimeoutMs = Optional.ofNullable(groupMaxSessionTimeoutMs);
            return this;
        }

        /**
         * The maximum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
         */
        public Builder groupMaxSessionTimeoutMs(Optional<? extends Long> groupMaxSessionTimeoutMs) {
            Utils.checkNotNull(groupMaxSessionTimeoutMs, "groupMaxSessionTimeoutMs");
            this.groupMaxSessionTimeoutMs = groupMaxSessionTimeoutMs;
            return this;
        }

        /**
         * The number of messages accumulated on a log partition before messages are flushed to disk
         */
        public Builder logFlushIntervalMessages(long logFlushIntervalMessages) {
            Utils.checkNotNull(logFlushIntervalMessages, "logFlushIntervalMessages");
            this.logFlushIntervalMessages = Optional.ofNullable(logFlushIntervalMessages);
            return this;
        }

        /**
         * The number of messages accumulated on a log partition before messages are flushed to disk
         */
        public Builder logFlushIntervalMessages(Optional<? extends Long> logFlushIntervalMessages) {
            Utils.checkNotNull(logFlushIntervalMessages, "logFlushIntervalMessages");
            this.logFlushIntervalMessages = logFlushIntervalMessages;
            return this;
        }

        /**
         * OIDC JWKS endpoint URL. By setting this the SASL SSL OAuth2/OIDC authentication is enabled. See also other options for SASL OAuth2/OIDC. 
         */
        public Builder saslOauthbearerJwksEndpointUrl(String saslOauthbearerJwksEndpointUrl) {
            Utils.checkNotNull(saslOauthbearerJwksEndpointUrl, "saslOauthbearerJwksEndpointUrl");
            this.saslOauthbearerJwksEndpointUrl = Optional.ofNullable(saslOauthbearerJwksEndpointUrl);
            return this;
        }

        /**
         * OIDC JWKS endpoint URL. By setting this the SASL SSL OAuth2/OIDC authentication is enabled. See also other options for SASL OAuth2/OIDC. 
         */
        public Builder saslOauthbearerJwksEndpointUrl(Optional<? extends String> saslOauthbearerJwksEndpointUrl) {
            Utils.checkNotNull(saslOauthbearerJwksEndpointUrl, "saslOauthbearerJwksEndpointUrl");
            this.saslOauthbearerJwksEndpointUrl = saslOauthbearerJwksEndpointUrl;
            return this;
        }

        /**
         * The maximum number of connections allowed from each ip address (defaults to 2147483647).
         */
        public Builder maxConnectionsPerIp(long maxConnectionsPerIp) {
            Utils.checkNotNull(maxConnectionsPerIp, "maxConnectionsPerIp");
            this.maxConnectionsPerIp = Optional.ofNullable(maxConnectionsPerIp);
            return this;
        }

        /**
         * The maximum number of connections allowed from each ip address (defaults to 2147483647).
         */
        public Builder maxConnectionsPerIp(Optional<? extends Long> maxConnectionsPerIp) {
            Utils.checkNotNull(maxConnectionsPerIp, "maxConnectionsPerIp");
            this.maxConnectionsPerIp = maxConnectionsPerIp;
            return this;
        }

        /**
         * Optional setting for the broker to use to verify that the JWT was created by the expected issuer.
         */
        public Builder saslOauthbearerExpectedIssuer(String saslOauthbearerExpectedIssuer) {
            Utils.checkNotNull(saslOauthbearerExpectedIssuer, "saslOauthbearerExpectedIssuer");
            this.saslOauthbearerExpectedIssuer = Optional.ofNullable(saslOauthbearerExpectedIssuer);
            return this;
        }

        /**
         * Optional setting for the broker to use to verify that the JWT was created by the expected issuer.
         */
        public Builder saslOauthbearerExpectedIssuer(Optional<? extends String> saslOauthbearerExpectedIssuer) {
            Utils.checkNotNull(saslOauthbearerExpectedIssuer, "saslOauthbearerExpectedIssuer");
            this.saslOauthbearerExpectedIssuer = saslOauthbearerExpectedIssuer;
            return this;
        }

        /**
         * The maximum size in bytes of the offset index
         */
        public Builder logIndexSizeMaxBytes(long logIndexSizeMaxBytes) {
            Utils.checkNotNull(logIndexSizeMaxBytes, "logIndexSizeMaxBytes");
            this.logIndexSizeMaxBytes = Optional.ofNullable(logIndexSizeMaxBytes);
            return this;
        }

        /**
         * The maximum size in bytes of the offset index
         */
        public Builder logIndexSizeMaxBytes(Optional<? extends Long> logIndexSizeMaxBytes) {
            Utils.checkNotNull(logIndexSizeMaxBytes, "logIndexSizeMaxBytes");
            this.logIndexSizeMaxBytes = logIndexSizeMaxBytes;
            return this;
        }

        /**
         * Enable auto creation of topics
         */
        public Builder autoCreateTopicsEnable(boolean autoCreateTopicsEnable) {
            Utils.checkNotNull(autoCreateTopicsEnable, "autoCreateTopicsEnable");
            this.autoCreateTopicsEnable = Optional.ofNullable(autoCreateTopicsEnable);
            return this;
        }

        /**
         * Enable auto creation of topics
         */
        public Builder autoCreateTopicsEnable(Optional<? extends Boolean> autoCreateTopicsEnable) {
            Utils.checkNotNull(autoCreateTopicsEnable, "autoCreateTopicsEnable");
            this.autoCreateTopicsEnable = autoCreateTopicsEnable;
            return this;
        }

        /**
         * The interval with which Kafka adds an entry to the offset index
         */
        public Builder logIndexIntervalBytes(long logIndexIntervalBytes) {
            Utils.checkNotNull(logIndexIntervalBytes, "logIndexIntervalBytes");
            this.logIndexIntervalBytes = Optional.ofNullable(logIndexIntervalBytes);
            return this;
        }

        /**
         * The interval with which Kafka adds an entry to the offset index
         */
        public Builder logIndexIntervalBytes(Optional<? extends Long> logIndexIntervalBytes) {
            Utils.checkNotNull(logIndexIntervalBytes, "logIndexIntervalBytes");
            this.logIndexIntervalBytes = logIndexIntervalBytes;
            return this;
        }

        /**
         * The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
         */
        public Builder replicaFetchMaxBytes(long replicaFetchMaxBytes) {
            Utils.checkNotNull(replicaFetchMaxBytes, "replicaFetchMaxBytes");
            this.replicaFetchMaxBytes = Optional.ofNullable(replicaFetchMaxBytes);
            return this;
        }

        /**
         * The number of bytes of messages to attempt to fetch for each partition (defaults to 1048576). This is not an absolute maximum, if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made.
         */
        public Builder replicaFetchMaxBytes(Optional<? extends Long> replicaFetchMaxBytes) {
            Utils.checkNotNull(replicaFetchMaxBytes, "replicaFetchMaxBytes");
            this.replicaFetchMaxBytes = replicaFetchMaxBytes;
            return this;
        }

        /**
         * Number of partitions for autocreated topics
         */
        public Builder numPartitions(long numPartitions) {
            Utils.checkNotNull(numPartitions, "numPartitions");
            this.numPartitions = Optional.ofNullable(numPartitions);
            return this;
        }

        /**
         * Number of partitions for autocreated topics
         */
        public Builder numPartitions(Optional<? extends Long> numPartitions) {
            Utils.checkNotNull(numPartitions, "numPartitions");
            this.numPartitions = numPartitions;
            return this;
        }

        /**
         * The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).
         */
        public Builder transactionStateLogSegmentBytes(long transactionStateLogSegmentBytes) {
            Utils.checkNotNull(transactionStateLogSegmentBytes, "transactionStateLogSegmentBytes");
            this.transactionStateLogSegmentBytes = Optional.ofNullable(transactionStateLogSegmentBytes);
            return this;
        }

        /**
         * The transaction topic segment bytes should be kept relatively small in order to facilitate faster log compaction and cache loads (defaults to 104857600 (100 mebibytes)).
         */
        public Builder transactionStateLogSegmentBytes(Optional<? extends Long> transactionStateLogSegmentBytes) {
            Utils.checkNotNull(transactionStateLogSegmentBytes, "transactionStateLogSegmentBytes");
            this.transactionStateLogSegmentBytes = transactionStateLogSegmentBytes;
            return this;
        }

        /**
         * Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
         */
        public Builder replicaFetchResponseMaxBytes(long replicaFetchResponseMaxBytes) {
            Utils.checkNotNull(replicaFetchResponseMaxBytes, "replicaFetchResponseMaxBytes");
            this.replicaFetchResponseMaxBytes = Optional.ofNullable(replicaFetchResponseMaxBytes);
            return this;
        }

        /**
         * Maximum bytes expected for the entire fetch response (defaults to 10485760). Records are fetched in batches, and if the first record batch in the first non-empty partition of the fetch is larger than this value, the record batch will still be returned to ensure that progress can be made. As such, this is not an absolute maximum.
         */
        public Builder replicaFetchResponseMaxBytes(Optional<? extends Long> replicaFetchResponseMaxBytes) {
            Utils.checkNotNull(replicaFetchResponseMaxBytes, "replicaFetchResponseMaxBytes");
            this.replicaFetchResponseMaxBytes = replicaFetchResponseMaxBytes;
            return this;
        }

        /**
         * Define whether the timestamp in the message is message create time or log append time.
         */
        public Builder logMessageTimestampType(LogMessageTimestampType logMessageTimestampType) {
            Utils.checkNotNull(logMessageTimestampType, "logMessageTimestampType");
            this.logMessageTimestampType = Optional.ofNullable(logMessageTimestampType);
            return this;
        }

        /**
         * Define whether the timestamp in the message is message create time or log append time.
         */
        public Builder logMessageTimestampType(Optional<? extends LogMessageTimestampType> logMessageTimestampType) {
            Utils.checkNotNull(logMessageTimestampType, "logMessageTimestampType");
            this.logMessageTimestampType = logMessageTimestampType;
            return this;
        }

        /**
         * Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.
         */
        public Builder connectionsMaxIdleMs(long connectionsMaxIdleMs) {
            Utils.checkNotNull(connectionsMaxIdleMs, "connectionsMaxIdleMs");
            this.connectionsMaxIdleMs = Optional.ofNullable(connectionsMaxIdleMs);
            return this;
        }

        /**
         * Idle connections timeout: the server socket processor threads close the connections that idle for longer than this.
         */
        public Builder connectionsMaxIdleMs(Optional<? extends Long> connectionsMaxIdleMs) {
            Utils.checkNotNull(connectionsMaxIdleMs, "connectionsMaxIdleMs");
            this.connectionsMaxIdleMs = connectionsMaxIdleMs;
            return this;
        }

        /**
         * The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
         */
        public Builder logFlushIntervalMs(long logFlushIntervalMs) {
            Utils.checkNotNull(logFlushIntervalMs, "logFlushIntervalMs");
            this.logFlushIntervalMs = Optional.ofNullable(logFlushIntervalMs);
            return this;
        }

        /**
         * The maximum time in ms that a message in any topic is kept in memory before flushed to disk. If not set, the value in log.flush.scheduler.interval.ms is used
         */
        public Builder logFlushIntervalMs(Optional<? extends Long> logFlushIntervalMs) {
            Utils.checkNotNull(logFlushIntervalMs, "logFlushIntervalMs");
            this.logFlushIntervalMs = logFlushIntervalMs;
            return this;
        }

        /**
         * Should pre allocate file when create new segment?
         */
        public Builder logPreallocate(boolean logPreallocate) {
            Utils.checkNotNull(logPreallocate, "logPreallocate");
            this.logPreallocate = Optional.ofNullable(logPreallocate);
            return this;
        }

        /**
         * Should pre allocate file when create new segment?
         */
        public Builder logPreallocate(Optional<? extends Boolean> logPreallocate) {
            Utils.checkNotNull(logPreallocate, "logPreallocate");
            this.logPreallocate = logPreallocate;
            return this;
        }

        /**
         * The amount of time to wait before deleting a file from the filesystem
         */
        public Builder logSegmentDeleteDelayMs(long logSegmentDeleteDelayMs) {
            Utils.checkNotNull(logSegmentDeleteDelayMs, "logSegmentDeleteDelayMs");
            this.logSegmentDeleteDelayMs = Optional.ofNullable(logSegmentDeleteDelayMs);
            return this;
        }

        /**
         * The amount of time to wait before deleting a file from the filesystem
         */
        public Builder logSegmentDeleteDelayMs(Optional<? extends Long> logSegmentDeleteDelayMs) {
            Utils.checkNotNull(logSegmentDeleteDelayMs, "logSegmentDeleteDelayMs");
            this.logSegmentDeleteDelayMs = logSegmentDeleteDelayMs;
            return this;
        }

        /**
         * The maximum size of message that the server can receive.
         */
        public Builder messageMaxBytes(long messageMaxBytes) {
            Utils.checkNotNull(messageMaxBytes, "messageMaxBytes");
            this.messageMaxBytes = Optional.ofNullable(messageMaxBytes);
            return this;
        }

        /**
         * The maximum size of message that the server can receive.
         */
        public Builder messageMaxBytes(Optional<? extends Long> messageMaxBytes) {
            Utils.checkNotNull(messageMaxBytes, "messageMaxBytes");
            this.messageMaxBytes = messageMaxBytes;
            return this;
        }

        /**
         * The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
         */
        public Builder groupInitialRebalanceDelayMs(long groupInitialRebalanceDelayMs) {
            Utils.checkNotNull(groupInitialRebalanceDelayMs, "groupInitialRebalanceDelayMs");
            this.groupInitialRebalanceDelayMs = Optional.ofNullable(groupInitialRebalanceDelayMs);
            return this;
        }

        /**
         * The amount of time, in milliseconds, the group coordinator will wait for more consumers to join a new group before performing the first rebalance. A longer delay means potentially fewer rebalances, but increases the time until processing begins. The default value for this is 3 seconds. During development and testing it might be desirable to set this to 0 in order to not delay test execution time.
         */
        public Builder groupInitialRebalanceDelayMs(Optional<? extends Long> groupInitialRebalanceDelayMs) {
            Utils.checkNotNull(groupInitialRebalanceDelayMs, "groupInitialRebalanceDelayMs");
            this.groupInitialRebalanceDelayMs = groupInitialRebalanceDelayMs;
            return this;
        }

        /**
         * The maximum size of local log segments that can grow for a partition before it gets eligible for deletion. If set to -2, the value of log.retention.bytes is used. The effective value should always be less than or equal to log.retention.bytes value.
         */
        public Builder logLocalRetentionBytes(long logLocalRetentionBytes) {
            Utils.checkNotNull(logLocalRetentionBytes, "logLocalRetentionBytes");
            this.logLocalRetentionBytes = Optional.ofNullable(logLocalRetentionBytes);
            return this;
        }

        /**
         * The maximum size of local log segments that can grow for a partition before it gets eligible for deletion. If set to -2, the value of log.retention.bytes is used. The effective value should always be less than or equal to log.retention.bytes value.
         */
        public Builder logLocalRetentionBytes(Optional<? extends Long> logLocalRetentionBytes) {
            Utils.checkNotNull(logLocalRetentionBytes, "logLocalRetentionBytes");
            this.logLocalRetentionBytes = logLocalRetentionBytes;
            return this;
        }

        /**
         * The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
         */
        public Builder logRollJitterMs(long logRollJitterMs) {
            Utils.checkNotNull(logRollJitterMs, "logRollJitterMs");
            this.logRollJitterMs = Optional.ofNullable(logRollJitterMs);
            return this;
        }

        /**
         * The maximum jitter to subtract from logRollTimeMillis (in milliseconds). If not set, the value in log.roll.jitter.hours is used
         */
        public Builder logRollJitterMs(Optional<? extends Long> logRollJitterMs) {
            Utils.checkNotNull(logRollJitterMs, "logRollJitterMs");
            this.logRollJitterMs = logRollJitterMs;
            return this;
        }

        /**
         * The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).
         */
        public Builder transactionRemoveExpiredTransactionCleanupIntervalMs(long transactionRemoveExpiredTransactionCleanupIntervalMs) {
            Utils.checkNotNull(transactionRemoveExpiredTransactionCleanupIntervalMs, "transactionRemoveExpiredTransactionCleanupIntervalMs");
            this.transactionRemoveExpiredTransactionCleanupIntervalMs = Optional.ofNullable(transactionRemoveExpiredTransactionCleanupIntervalMs);
            return this;
        }

        /**
         * The interval at which to remove transactions that have expired due to transactional.id.expiration.ms passing (defaults to 3600000 (1 hour)).
         */
        public Builder transactionRemoveExpiredTransactionCleanupIntervalMs(Optional<? extends Long> transactionRemoveExpiredTransactionCleanupIntervalMs) {
            Utils.checkNotNull(transactionRemoveExpiredTransactionCleanupIntervalMs, "transactionRemoveExpiredTransactionCleanupIntervalMs");
            this.transactionRemoveExpiredTransactionCleanupIntervalMs = transactionRemoveExpiredTransactionCleanupIntervalMs;
            return this;
        }

        /**
         * Replication factor for autocreated topics
         */
        public Builder defaultReplicationFactor(long defaultReplicationFactor) {
            Utils.checkNotNull(defaultReplicationFactor, "defaultReplicationFactor");
            this.defaultReplicationFactor = Optional.ofNullable(defaultReplicationFactor);
            return this;
        }

        /**
         * Replication factor for autocreated topics
         */
        public Builder defaultReplicationFactor(Optional<? extends Long> defaultReplicationFactor) {
            Utils.checkNotNull(defaultReplicationFactor, "defaultReplicationFactor");
            this.defaultReplicationFactor = defaultReplicationFactor;
            return this;
        }

        /**
         * The maximum time before a new log segment is rolled out (in milliseconds).
         */
        public Builder logRollMs(long logRollMs) {
            Utils.checkNotNull(logRollMs, "logRollMs");
            this.logRollMs = Optional.ofNullable(logRollMs);
            return this;
        }

        /**
         * The maximum time before a new log segment is rolled out (in milliseconds).
         */
        public Builder logRollMs(Optional<? extends Long> logRollMs) {
            Utils.checkNotNull(logRollMs, "logRollMs");
            this.logRollMs = logRollMs;
            return this;
        }

        /**
         * The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
         */
        public Builder producerPurgatoryPurgeIntervalRequests(long producerPurgatoryPurgeIntervalRequests) {
            Utils.checkNotNull(producerPurgatoryPurgeIntervalRequests, "producerPurgatoryPurgeIntervalRequests");
            this.producerPurgatoryPurgeIntervalRequests = Optional.ofNullable(producerPurgatoryPurgeIntervalRequests);
            return this;
        }

        /**
         * The purge interval (in number of requests) of the producer request purgatory(defaults to 1000).
         */
        public Builder producerPurgatoryPurgeIntervalRequests(Optional<? extends Long> producerPurgatoryPurgeIntervalRequests) {
            Utils.checkNotNull(producerPurgatoryPurgeIntervalRequests, "producerPurgatoryPurgeIntervalRequests");
            this.producerPurgatoryPurgeIntervalRequests = producerPurgatoryPurgeIntervalRequests;
            return this;
        }

        /**
         * The maximum size of the log before deleting messages
         */
        public Builder logRetentionBytes(long logRetentionBytes) {
            Utils.checkNotNull(logRetentionBytes, "logRetentionBytes");
            this.logRetentionBytes = Optional.ofNullable(logRetentionBytes);
            return this;
        }

        /**
         * The maximum size of the log before deleting messages
         */
        public Builder logRetentionBytes(Optional<? extends Long> logRetentionBytes) {
            Utils.checkNotNull(logRetentionBytes, "logRetentionBytes");
            this.logRetentionBytes = logRetentionBytes;
            return this;
        }

        /**
         * When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
         */
        public Builder minInsyncReplicas(long minInsyncReplicas) {
            Utils.checkNotNull(minInsyncReplicas, "minInsyncReplicas");
            this.minInsyncReplicas = Optional.ofNullable(minInsyncReplicas);
            return this;
        }

        /**
         * When a producer sets acks to 'all' (or '-1'), min.insync.replicas specifies the minimum number of replicas that must acknowledge a write for the write to be considered successful.
         */
        public Builder minInsyncReplicas(Optional<? extends Long> minInsyncReplicas) {
            Utils.checkNotNull(minInsyncReplicas, "minInsyncReplicas");
            this.minInsyncReplicas = minInsyncReplicas;
            return this;
        }

        /**
         * Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
         */
        public Builder compressionType(CompressionType compressionType) {
            Utils.checkNotNull(compressionType, "compressionType");
            this.compressionType = Optional.ofNullable(compressionType);
            return this;
        }

        /**
         * Specify the final compression type for a given topic. This configuration accepts the standard compression codecs ('gzip', 'snappy', 'lz4', 'zstd'). It additionally accepts 'uncompressed' which is equivalent to no compression; and 'producer' which means retain the original compression codec set by the producer.
         */
        public Builder compressionType(Optional<? extends CompressionType> compressionType) {
            Utils.checkNotNull(compressionType, "compressionType");
            this.compressionType = compressionType;
            return this;
        }

        /**
         * The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
         */
        public Builder logMessageTimestampDifferenceMaxMs(long logMessageTimestampDifferenceMaxMs) {
            Utils.checkNotNull(logMessageTimestampDifferenceMaxMs, "logMessageTimestampDifferenceMaxMs");
            this.logMessageTimestampDifferenceMaxMs = Optional.ofNullable(logMessageTimestampDifferenceMaxMs);
            return this;
        }

        /**
         * The maximum difference allowed between the timestamp when a broker receives a message and the timestamp specified in the message
         */
        public Builder logMessageTimestampDifferenceMaxMs(Optional<? extends Long> logMessageTimestampDifferenceMaxMs) {
            Utils.checkNotNull(logMessageTimestampDifferenceMaxMs, "logMessageTimestampDifferenceMaxMs");
            this.logMessageTimestampDifferenceMaxMs = logMessageTimestampDifferenceMaxMs;
            return this;
        }

        /**
         * The number of milliseconds to keep the local log segments before it gets eligible for deletion. If set to -2, the value of log.retention.ms is used. The effective value should always be less than or equal to log.retention.ms value.
         */
        public Builder logLocalRetentionMs(long logLocalRetentionMs) {
            Utils.checkNotNull(logLocalRetentionMs, "logLocalRetentionMs");
            this.logLocalRetentionMs = Optional.ofNullable(logLocalRetentionMs);
            return this;
        }

        /**
         * The number of milliseconds to keep the local log segments before it gets eligible for deletion. If set to -2, the value of log.retention.ms is used. The effective value should always be less than or equal to log.retention.ms value.
         */
        public Builder logLocalRetentionMs(Optional<? extends Long> logLocalRetentionMs) {
            Utils.checkNotNull(logLocalRetentionMs, "logLocalRetentionMs");
            this.logLocalRetentionMs = logLocalRetentionMs;
            return this;
        }

        /**
         * This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. 
         */
        public Builder logMessageDownconversionEnable(boolean logMessageDownconversionEnable) {
            Utils.checkNotNull(logMessageDownconversionEnable, "logMessageDownconversionEnable");
            this.logMessageDownconversionEnable = Optional.ofNullable(logMessageDownconversionEnable);
            return this;
        }

        /**
         * This configuration controls whether down-conversion of message formats is enabled to satisfy consume requests. 
         */
        public Builder logMessageDownconversionEnable(Optional<? extends Boolean> logMessageDownconversionEnable) {
            Utils.checkNotNull(logMessageDownconversionEnable, "logMessageDownconversionEnable");
            this.logMessageDownconversionEnable = logMessageDownconversionEnable;
            return this;
        }

        /**
         * Name of the scope from which to extract the subject claim from the JWT. Defaults to sub.
         */
        public Builder saslOauthbearerSubClaimName(String saslOauthbearerSubClaimName) {
            Utils.checkNotNull(saslOauthbearerSubClaimName, "saslOauthbearerSubClaimName");
            this.saslOauthbearerSubClaimName = Optional.ofNullable(saslOauthbearerSubClaimName);
            return this;
        }

        /**
         * Name of the scope from which to extract the subject claim from the JWT. Defaults to sub.
         */
        public Builder saslOauthbearerSubClaimName(Optional<? extends String> saslOauthbearerSubClaimName) {
            Utils.checkNotNull(saslOauthbearerSubClaimName, "saslOauthbearerSubClaimName");
            this.saslOauthbearerSubClaimName = saslOauthbearerSubClaimName;
            return this;
        }

        /**
         * The maximum number of incremental fetch sessions that the broker will maintain.
         */
        public Builder maxIncrementalFetchSessionCacheSlots(long maxIncrementalFetchSessionCacheSlots) {
            Utils.checkNotNull(maxIncrementalFetchSessionCacheSlots, "maxIncrementalFetchSessionCacheSlots");
            this.maxIncrementalFetchSessionCacheSlots = Optional.ofNullable(maxIncrementalFetchSessionCacheSlots);
            return this;
        }

        /**
         * The maximum number of incremental fetch sessions that the broker will maintain.
         */
        public Builder maxIncrementalFetchSessionCacheSlots(Optional<? extends Long> maxIncrementalFetchSessionCacheSlots) {
            Utils.checkNotNull(maxIncrementalFetchSessionCacheSlots, "maxIncrementalFetchSessionCacheSlots");
            this.maxIncrementalFetchSessionCacheSlots = maxIncrementalFetchSessionCacheSlots;
            return this;
        }

        /**
         * The number of hours to keep a log file before deleting it
         */
        public Builder logRetentionHours(long logRetentionHours) {
            Utils.checkNotNull(logRetentionHours, "logRetentionHours");
            this.logRetentionHours = Optional.ofNullable(logRetentionHours);
            return this;
        }

        /**
         * The number of hours to keep a log file before deleting it
         */
        public Builder logRetentionHours(Optional<? extends Long> logRetentionHours) {
            Utils.checkNotNull(logRetentionHours, "logRetentionHours");
            this.logRetentionHours = logRetentionHours;
            return this;
        }

        /**
         * The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
         */
        public Builder groupMinSessionTimeoutMs(long groupMinSessionTimeoutMs) {
            Utils.checkNotNull(groupMinSessionTimeoutMs, "groupMinSessionTimeoutMs");
            this.groupMinSessionTimeoutMs = Optional.ofNullable(groupMinSessionTimeoutMs);
            return this;
        }

        /**
         * The minimum allowed session timeout for registered consumers. Longer timeouts give consumers more time to process messages in between heartbeats at the cost of a longer time to detect failures.
         */
        public Builder groupMinSessionTimeoutMs(Optional<? extends Long> groupMinSessionTimeoutMs) {
            Utils.checkNotNull(groupMinSessionTimeoutMs, "groupMinSessionTimeoutMs");
            this.groupMinSessionTimeoutMs = groupMinSessionTimeoutMs;
            return this;
        }

        /**
         * The maximum number of bytes in a socket request (defaults to 104857600).
         */
        public Builder socketRequestMaxBytes(long socketRequestMaxBytes) {
            Utils.checkNotNull(socketRequestMaxBytes, "socketRequestMaxBytes");
            this.socketRequestMaxBytes = Optional.ofNullable(socketRequestMaxBytes);
            return this;
        }

        /**
         * The maximum number of bytes in a socket request (defaults to 104857600).
         */
        public Builder socketRequestMaxBytes(Optional<? extends Long> socketRequestMaxBytes) {
            Utils.checkNotNull(socketRequestMaxBytes, "socketRequestMaxBytes");
            this.socketRequestMaxBytes = socketRequestMaxBytes;
            return this;
        }

        /**
         * The maximum size of a single log file
         */
        public Builder logSegmentBytes(long logSegmentBytes) {
            Utils.checkNotNull(logSegmentBytes, "logSegmentBytes");
            this.logSegmentBytes = Optional.ofNullable(logSegmentBytes);
            return this;
        }

        /**
         * The maximum size of a single log file
         */
        public Builder logSegmentBytes(Optional<? extends Long> logSegmentBytes) {
            Utils.checkNotNull(logSegmentBytes, "logSegmentBytes");
            this.logSegmentBytes = logSegmentBytes;
            return this;
        }

        public Builder logCleanupAndCompaction(ConfigureLogCleanerForTopicCompaction logCleanupAndCompaction) {
            Utils.checkNotNull(logCleanupAndCompaction, "logCleanupAndCompaction");
            this.logCleanupAndCompaction = Optional.ofNullable(logCleanupAndCompaction);
            return this;
        }

        public Builder logCleanupAndCompaction(Optional<? extends ConfigureLogCleanerForTopicCompaction> logCleanupAndCompaction) {
            Utils.checkNotNull(logCleanupAndCompaction, "logCleanupAndCompaction");
            this.logCleanupAndCompaction = logCleanupAndCompaction;
            return this;
        }

        /**
         * Log retention window in minutes for offsets topic
         */
        public Builder offsetsRetentionMinutes(long offsetsRetentionMinutes) {
            Utils.checkNotNull(offsetsRetentionMinutes, "offsetsRetentionMinutes");
            this.offsetsRetentionMinutes = Optional.ofNullable(offsetsRetentionMinutes);
            return this;
        }

        /**
         * Log retention window in minutes for offsets topic
         */
        public Builder offsetsRetentionMinutes(Optional<? extends Long> offsetsRetentionMinutes) {
            Utils.checkNotNull(offsetsRetentionMinutes, "offsetsRetentionMinutes");
            this.offsetsRetentionMinutes = offsetsRetentionMinutes;
            return this;
        }

        /**
         * The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
         */
        public Builder logRetentionMs(long logRetentionMs) {
            Utils.checkNotNull(logRetentionMs, "logRetentionMs");
            this.logRetentionMs = Optional.ofNullable(logRetentionMs);
            return this;
        }

        /**
         * The number of milliseconds to keep a log file before deleting it (in milliseconds), If not set, the value in log.retention.minutes is used. If set to -1, no time limit is applied.
         */
        public Builder logRetentionMs(Optional<? extends Long> logRetentionMs) {
            Utils.checkNotNull(logRetentionMs, "logRetentionMs");
            this.logRetentionMs = logRetentionMs;
            return this;
        }
        
        public JsonSchemaKafka build() {
            return new JsonSchemaKafka(
                saslOauthbearerExpectedAudience,
                groupMaxSessionTimeoutMs,
                logFlushIntervalMessages,
                saslOauthbearerJwksEndpointUrl,
                maxConnectionsPerIp,
                saslOauthbearerExpectedIssuer,
                logIndexSizeMaxBytes,
                autoCreateTopicsEnable,
                logIndexIntervalBytes,
                replicaFetchMaxBytes,
                numPartitions,
                transactionStateLogSegmentBytes,
                replicaFetchResponseMaxBytes,
                logMessageTimestampType,
                connectionsMaxIdleMs,
                logFlushIntervalMs,
                logPreallocate,
                logSegmentDeleteDelayMs,
                messageMaxBytes,
                groupInitialRebalanceDelayMs,
                logLocalRetentionBytes,
                logRollJitterMs,
                transactionRemoveExpiredTransactionCleanupIntervalMs,
                defaultReplicationFactor,
                logRollMs,
                producerPurgatoryPurgeIntervalRequests,
                logRetentionBytes,
                minInsyncReplicas,
                compressionType,
                logMessageTimestampDifferenceMaxMs,
                logLocalRetentionMs,
                logMessageDownconversionEnable,
                saslOauthbearerSubClaimName,
                maxIncrementalFetchSessionCacheSlots,
                logRetentionHours,
                groupMinSessionTimeoutMs,
                socketRequestMaxBytes,
                logSegmentBytes,
                logCleanupAndCompaction,
                offsetsRetentionMinutes,
                logRetentionMs);
        }
    }
}

